{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# MERT LoRA Fine-tuning for Meter Classification\n\n**GPU**: Runtime → Change runtime type → T4 GPU (free) or A100 (Pro)\n\nThis notebook:\n1. Downloads METER2800 dataset from Harvard Dataverse\n2. Downloads WIKIMETER (curated songs from YouTube: 3/4, 4/4, 5/x, 7/x, 9/x, 11/x)\n3. Fine-tunes MERT with LoRA for multi-label meter classification\n\n**Estimated time**: ~2-3h on T4 (95M), ~5h on A100 (330M)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers peft librosa scikit-learn tqdm yt-dlp\n",
    "!apt-get -qq install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'NO GPU'}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"No GPU! Go to Runtime → Change runtime type → T4 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download METER2800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import ssl\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"/content/data/meter2800\")\n",
    "AUDIO_DIR = DATA_DIR / \"audio\"\n",
    "DOWNLOADS_DIR = DATA_DIR / \"downloads\"\n",
    "AUDIO_EXTENSIONS = {\".wav\", \".mp3\", \".ogg\", \".flac\", \".oga\", \".opus\", \".aiff\", \".aif\"}\n",
    "\n",
    "DOI = \"doi:10.7910/DVN/0CLXBQ\"\n",
    "API_BASE = \"https://dataverse.harvard.edu/api\"\n",
    "DATASET_URL = f\"{API_BASE}/datasets/:persistentId/?persistentId={DOI}\"\n",
    "TAR_FILES = {\"FMA.tar.gz\", \"MAG.tar.gz\", \"OWN.tar.gz\"}\n",
    "\n",
    "\n",
    "def api_request(url, max_retries=3):\n",
    "    ctx = ssl.create_default_context()\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            req = urllib.request.Request(url, headers={\"User-Agent\": \"RhythmAnalyzer/1.0\", \"Accept\": \"application/json\"})\n",
    "            with urllib.request.urlopen(req, timeout=30, context=ctx) as resp:\n",
    "                return resp.read()\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 * (2 ** attempt))\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "\n",
    "def download_dataverse_file(file_id, dest, expected_size=0):\n",
    "    url = f\"{API_BASE}/access/datafile/{file_id}\"\n",
    "    ctx = ssl.create_default_context()\n",
    "    req = urllib.request.Request(url, headers={\"User-Agent\": \"RhythmAnalyzer/1.0\"})\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with urllib.request.urlopen(req, timeout=300, context=ctx) as resp:\n",
    "        dest.write_bytes(resp.read())\n",
    "    return dest.exists()\n",
    "\n",
    "\n",
    "def extract_tar(tar_path, audio_dir):\n",
    "    audio_dir.mkdir(parents=True, exist_ok=True)\n",
    "    count = 0\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if not member.isfile():\n",
    "                continue\n",
    "            name = Path(member.name).name\n",
    "            if Path(name).suffix.lower() not in AUDIO_EXTENSIONS:\n",
    "                continue\n",
    "            dest = audio_dir / name\n",
    "            if dest.exists():\n",
    "                parent = Path(member.name).parent.name\n",
    "                dest = audio_dir / f\"{parent}_{name}\"\n",
    "            with tar.extractfile(member) as src:\n",
    "                if src:\n",
    "                    dest.write_bytes(src.read())\n",
    "                    count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "# Check if already downloaded\n",
    "if AUDIO_DIR.exists() and len(list(AUDIO_DIR.glob(\"*\"))) > 2000:\n",
    "    print(f\"METER2800 already downloaded: {len(list(AUDIO_DIR.glob('*')))} files\")\n",
    "else:\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    DOWNLOADS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    AUDIO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get file list\n",
    "    print(\"Fetching METER2800 metadata...\")\n",
    "    metadata = json.loads(api_request(DATASET_URL))\n",
    "    files = metadata[\"data\"][\"latestVersion\"][\"files\"]\n",
    "    print(f\"Found {len(files)} files\")\n",
    "\n",
    "    for f in files:\n",
    "        df = f[\"dataFile\"]\n",
    "        fname = df[\"filename\"]\n",
    "\n",
    "        if fname in TAR_FILES:\n",
    "            dest = DOWNLOADS_DIR / fname\n",
    "            if not dest.exists():\n",
    "                print(f\"Downloading {fname}...\", end=\" \", flush=True)\n",
    "                download_dataverse_file(df[\"id\"], dest, df.get(\"filesize\", 0))\n",
    "                print(\"OK\")\n",
    "        elif fname.endswith((\".csv\", \".tab\", \".tsv\")):\n",
    "            dest = DATA_DIR / fname\n",
    "            if not dest.exists():\n",
    "                print(f\"Downloading {fname}...\", end=\" \", flush=True)\n",
    "                download_dataverse_file(df[\"id\"], dest)\n",
    "                print(\"OK\")\n",
    "\n",
    "    # Extract\n",
    "    total = 0\n",
    "    for tar_path in sorted(DOWNLOADS_DIR.glob(\"*.tar.gz\")):\n",
    "        if tar_path.name in TAR_FILES:\n",
    "            print(f\"Extracting {tar_path.name}...\", end=\" \", flush=True)\n",
    "            count = extract_tar(tar_path, AUDIO_DIR)\n",
    "            print(f\"{count} files\")\n",
    "            total += count\n",
    "    print(f\"\\nTotal extracted: {total} audio files\")\n",
    "\n",
    "# Verify\n",
    "n_audio = len([f for f in AUDIO_DIR.iterdir() if f.suffix.lower() in AUDIO_EXTENSIONS])\n",
    "n_tabs = len(list(DATA_DIR.glob(\"*.tab\")))\n",
    "print(f\"\\nMETER2800: {n_audio} audio files, {n_tabs} label files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Download WIKIMETER (YouTube)\n\nCurated songs with known time signatures: 3/4, 4/4, 5/x, 7/x, 9/x, 11/x + polyrhythmic.\nExpected duration per song filters out albums/compilations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import re\nimport subprocess\nimport tempfile\n\nWIKIMETER_DIR = Path(\"/content/data/wikimeter\")\nWIKIMETER_AUDIO = WIKIMETER_DIR / \"audio\"\nWIKIMETER_TAB = WIKIMETER_DIR / \"data_wikimeter.tab\"\nMETER_LABELS = {3: \"three\", 4: \"four\", 5: \"five\", 7: \"seven\", 9: \"nine\", 11: \"eleven\"}\nMAX_SEGMENTS = 25\nDURATION_TOLERANCE = 2.0  # Accept 0.5x–2.0x expected duration\nMAX_VIDEO_DURATION_FALLBACK = 900\n\n# (artist, title, meters, search_query_override, expected_duration_s)\nSONGS = [\n    # === 3/4 ===\n    (\"Strauss II\", \"The Blue Danube\", [3], \"Johann Strauss Blue Danube waltz\", 600),\n    (\"Strauss II\", \"Tales from the Vienna Woods\", [3], \"Strauss Tales Vienna Woods waltz\", 720),\n    (\"Strauss II\", \"Emperor Waltz\", [3], \"Strauss Emperor Waltz Kaiserwalzer\", 660),\n    (\"Chopin\", \"Waltz in C-sharp minor Op 64 No 2\", [3], \"Chopin Waltz Op 64 No 2\", 210),\n    (\"Chopin\", \"Minute Waltz\", [3], \"Chopin Minute Waltz Op 64 No 1\", 120),\n    (\"Chopin\", \"Grande Valse Brillante\", [3], \"Chopin Grande Valse Brillante Op 18\", 300),\n    (\"Chopin\", \"Waltz in A minor\", [3], \"Chopin Waltz A minor B 150\", 180),\n    (\"Tchaikovsky\", \"Waltz of the Flowers\", [3], \"Tchaikovsky Waltz of the Flowers Nutcracker\", 420),\n    (\"Tchaikovsky\", \"Sleeping Beauty Waltz\", [3], \"Tchaikovsky Sleeping Beauty Waltz\", 360),\n    (\"Tchaikovsky\", \"Swan Lake Waltz\", [3], \"Tchaikovsky Swan Lake Waltz\", 390),\n    (\"Shostakovich\", \"Waltz No 2\", [3], \"Shostakovich Waltz No 2\", 210),\n    (\"Khachaturian\", \"Masquerade Waltz\", [3], \"Khachaturian Masquerade Waltz\", 270),\n    (\"Ravel\", \"La Valse\", [3], \"Ravel La Valse orchestral\", 780),\n    (\"Brahms\", \"Waltz in A-flat major Op 39 No 15\", [3], \"Brahms Waltz Op 39 No 15\", 120),\n    (\"The Beatles\", \"Norwegian Wood\", [3], None, 125),\n    (\"Leonard Cohen\", \"Take This Waltz\", [3], None, 420),\n    (\"Norah Jones\", \"Come Away With Me\", [3], None, 198),\n    (\"Jeff Buckley\", \"Lilac Wine\", [3], None, 280),\n    (\"Radiohead\", \"Codex\", [3], None, 280),\n    (\"Elliott Smith\", \"Waltz No 2\", [3], \"Elliott Smith Waltz No 2 XO\", 270),\n    (\"Damien Rice\", \"The Blower's Daughter\", [3], \"Damien Rice Blowers Daughter\", 260),\n    (\"Mazzy Star\", \"Fade Into You\", [3], None, 290),\n    (\"R.E.M.\", \"Everybody Hurts\", [3], None, 318),\n    (\"Counting Crows\", \"A Long December\", [3], None, 330),\n    (\"Traditional\", \"Greensleeves\", [3], \"Greensleeves traditional\", 240),\n    (\"Traditional\", \"Scarborough Fair\", [3], \"Scarborough Fair traditional\", 210),\n    (\"Traditional\", \"Danny Boy\", [3], \"Danny Boy traditional Irish\", 240),\n    (\"Traditional\", \"Amazing Grace\", [3], \"Amazing Grace traditional\", 300),\n    (\"Traditional\", \"Edelweiss\", [3], \"Edelweiss Sound of Music\", 150),\n    # === 4/4 ===\n    (\"Queen\", \"We Will Rock You\", [4], None, 122),\n    (\"Queen\", \"Another One Bites the Dust\", [4], None, 215),\n    (\"AC/DC\", \"Back in Black\", [4], None, 255),\n    (\"Deep Purple\", \"Smoke on the Water\", [4], None, 340),\n    (\"Led Zeppelin\", \"Whole Lotta Love\", [4], None, 333),\n    (\"The Rolling Stones\", \"Satisfaction\", [4], \"Rolling Stones Satisfaction\", 224),\n    (\"Nirvana\", \"Smells Like Teen Spirit\", [4], None, 301),\n    (\"Metallica\", \"Enter Sandman\", [4], None, 331),\n    (\"Guns N Roses\", \"Sweet Child O Mine\", [4], \"Guns N Roses Sweet Child O Mine\", 356),\n    (\"The White Stripes\", \"Seven Nation Army\", [4], None, 232),\n    (\"Michael Jackson\", \"Billie Jean\", [4], None, 294),\n    (\"Michael Jackson\", \"Beat It\", [4], None, 258),\n    (\"Stevie Wonder\", \"Superstition\", [4], None, 245),\n    (\"Bee Gees\", \"Stayin Alive\", [4], \"Bee Gees Stayin Alive\", 285),\n    (\"ABBA\", \"Dancing Queen\", [4], None, 231),\n    (\"Daft Punk\", \"Get Lucky\", [4], None, 369),\n    (\"Daft Punk\", \"Around the World\", [4], None, 427),\n    (\"Bruno Mars\", \"Uptown Funk\", [4], None, 270),\n    (\"Pharrell Williams\", \"Happy\", [4], None, 233),\n    (\"Marvin Gaye\", \"Aint No Mountain High Enough\", [4], \"Marvin Gaye Aint No Mountain High Enough\", 150),\n    (\"Kraftwerk\", \"The Model\", [4], None, 220),\n    (\"Kraftwerk\", \"Autobahn\", [4], \"Kraftwerk Autobahn\", 660),\n    (\"New Order\", \"Blue Monday\", [4], None, 442),\n    (\"Depeche Mode\", \"Personal Jesus\", [4], None, 295),\n    (\"The Prodigy\", \"Firestarter\", [4], None, 280),\n    (\"James Brown\", \"I Got You\", [4], \"James Brown I Got You I Feel Good\", 167),\n    (\"Parliament\", \"Give Up the Funk\", [4], \"Parliament Give Up the Funk\", 348),\n    (\"Grandmaster Flash\", \"The Message\", [4], None, 445),\n    (\"A Tribe Called Quest\", \"Can I Kick It\", [4], None, 260),\n    # === 5/x ===\n    (\"Dave Brubeck\", \"Take Five\", [5], None, 325),\n    (\"Paul Desmond\", \"Take Ten\", [5], \"Paul Desmond Take Ten\", 340),\n    (\"Brubeck\", \"Three to Get Ready\", [5], \"Dave Brubeck Three to Get Ready\", 340),\n    (\"Chick Corea\", \"Spain\", [5], \"Chick Corea Spain\", 600),\n    (\"Radiohead\", \"15 Step\", [5], None, 237),\n    (\"Radiohead\", \"Morning Bell\", [5], None, 270),\n    (\"Radiohead\", \"Everything in Its Right Place\", [5], None, 250),\n    (\"Radiohead\", \"Sail to the Moon\", [5], None, 290),\n    (\"Gorillaz\", \"5/4\", [5], \"Gorillaz 5/4\", 241),\n    (\"Jethro Tull\", \"Living in the Past\", [5], None, 205),\n    (\"Sting\", \"Seven Days\", [5], None, 290),\n    (\"Nick Drake\", \"River Man\", [5], None, 275),\n    (\"The Mars Volta\", \"Inertiatic ESP\", [5], None, 230),\n    (\"Sufjan Stevens\", \"A Good Man Is Hard to Find\", [5], None, 300),\n    (\"Donovan\", \"Atlantis\", [5], None, 295),\n    (\"Soundgarden\", \"My Wave\", [5], \"Soundgarden My Wave\", 312),\n    (\"Tame Impala\", \"Apocalypse Dreams\", [5], None, 390),\n    (\"Lalo Schifrin\", \"Mission Impossible Theme\", [5], \"Mission Impossible theme original\", 180),\n    (\"Chopin\", \"Piano Sonata No 1 Larghetto\", [5], \"Chopin Piano Sonata No 1 Op 4 Larghetto 5/4\", 480),\n    (\"Tchaikovsky\", \"Symphony No 6 Movement 2\", [5], \"Tchaikovsky Symphony 6 second movement 5/4\", 510),\n    (\"Dream Theater\", \"The Mirror\", [5], None, 660),\n    (\"Animals as Leaders\", \"CAFO\", [5], None, 370),\n    (\"King Crimson\", \"Discipline\", [5], \"King Crimson Discipline\", 305),\n    (\"Björk\", \"Army of Me\", [5], None, 224),\n    (\"Béla Fleck\", \"Sinister Minister\", [5], \"Bela Fleck Sinister Minister\", 360),\n    (\"Mike Oldfield\", \"Tubular Bells Part 1\", [5], \"Mike Oldfield Tubular Bells opening 5/4\", 600),\n    (\"Vulfpeck\", \"Dean Town\", [5], None, 210),\n    (\"Jacob Collier\", \"In My Room\", [5], \"Jacob Collier In My Room\", 300),\n    (\"Traditional\", \"Eleno Mome\", [5], \"Eleno Mome Bulgarian folk\", 240),\n    (\"Traditional\", \"Paidushko Horo\", [5], \"Paidushko Horo Bulgarian folk\", 240),\n    # === 7/x ===\n    (\"Pink Floyd\", \"Money\", [7], None, 382),\n    (\"Peter Gabriel\", \"Solsbury Hill\", [7], None, 260),\n    (\"Soundgarden\", \"Outshined\", [7], \"Soundgarden Outshined\", 312),\n    (\"The Beatles\", \"All You Need Is Love\", [7], \"Beatles All You Need Is Love\", 237),\n    (\"Radiohead\", \"2 + 2 = 5\", [7], \"Radiohead 2+2=5\", 202),\n    (\"Rush\", \"Tom Sawyer\", [7], \"Rush Tom Sawyer\", 276),\n    (\"Gentle Giant\", \"The Runaway\", [7], \"Gentle Giant The Runaway\", 300),\n    (\"Alice in Chains\", \"Them Bones\", [7], \"Alice in Chains Them Bones\", 147),\n    (\"King Crimson\", \"Frame by Frame\", [7], \"King Crimson Frame by Frame\", 310),\n    (\"Opeth\", \"The Drapery Falls\", [7], None, 630),\n    (\"Gentle Giant\", \"Knots\", [7], \"Gentle Giant Knots\", 300),\n    (\"Robert Fripp\", \"Exposure\", [7], \"Robert Fripp Exposure\", 260),\n    (\"Dave Holland\", \"Conference of the Birds\", [7], \"Dave Holland Conference of the Birds\", 480),\n    (\"John McLaughlin\", \"Meeting of the Spirits\", [7], \"Mahavishnu Orchestra Meeting of the Spirits\", 420),\n    (\"Traditional\", \"Rachenitsa\", [7], \"Rachenitsa Bulgarian folk 7/8\", 240),\n    (\"Traditional\", \"Makedonsko Devojche\", [7], \"Makedonsko Devojche folk 7/8\", 240),\n    (\"Traditional\", \"Chetvorno Horo\", [7], \"Chetvorno Horo Bulgarian 7/8\", 240),\n    (\"Traditional\", \"Lesnoto\", [7], \"Lesnoto Macedonian 7/8\", 240),\n    (\"Traditional\", \"Ivailo\", [7], \"Ivailo Bulgarian folk 7/8\", 240),\n    (\"Traditional\", \"Pravo Horo\", [7], \"Pravo Horo Bulgarian\", 240),\n    (\"Goran Bregović\", \"Mesečina\", [7], \"Goran Bregovic Mesecina\", 240),\n    (\"Fanfare Ciocărlia\", \"Born to Be Wild\", [7], \"Fanfare Ciocarlia Born to Be Wild\", 270),\n    (\"Bernstein\", \"America from West Side Story\", [7], \"Bernstein America West Side Story\", 300),\n    (\"Hans Zimmer\", \"Mombasa\", [7], \"Hans Zimmer Mombasa Inception\", 295),\n    (\"Bear McCreary\", \"BSG Main Theme\", [7], \"Bear McCreary Battlestar Galactica theme\", 240),\n    (\"Aimee Mann\", \"Momentum\", [7], None, 260),\n    (\"Joni Mitchell\", \"The Silky Veils of Ardor\", [7], None, 240),\n    (\"Broken Social Scene\", \"7/4 Shoreline\", [7], \"Broken Social Scene 7/4 Shoreline\", 260),\n    (\"Iron Maiden\", \"The Loneliness of the Long Distance Runner\", [7], None, 390),\n    (\"Led Zeppelin\", \"The Ocean\", [7], \"Led Zeppelin The Ocean\", 266),\n    (\"Jeff Beck\", \"Led Boots\", [7], None, 340),\n    (\"Porcupine Tree\", \"The Sound of Muzak\", [7], None, 290),\n    # === 9/8 ===\n    (\"Dave Brubeck\", \"Blue Rondo à la Turk\", [9], \"Dave Brubeck Blue Rondo a la Turk\", 402),\n    (\"Traditional\", \"Daichovo Horo\", [9], \"Daichovo Horo Bulgarian 9/8\", 240),\n    (\"Traditional\", \"Zeimbekiko\", [9], \"Zeimbekiko Greek dance 9/8\", 300),\n    (\"Traditional\", \"Karsilama\", [9], \"Karsilama Turkish 9/8\", 240),\n    (\"Traditional\", \"Arap\", [9], \"Arap Turkish 9/8 dance\", 240),\n    (\"Bartók\", \"Six Dances in Bulgarian Rhythm No 4\", [9], \"Bartok Mikrokosmos 151 Bulgarian Rhythm 4\", 90),\n    (\"Bartók\", \"Six Dances in Bulgarian Rhythm No 5\", [9], \"Bartok Mikrokosmos 152 Bulgarian Rhythm 5\", 90),\n    (\"Toto\", \"Mushanga\", [9], \"Toto Mushanga\", 360),\n    (\"Muse\", \"Butterflies and Hurricanes\", [9], \"Muse Butterflies and Hurricanes\", 330),\n    (\"Mahler\", \"Symphony No 9 Rondo Burleske\", [9], \"Mahler Symphony 9 Rondo Burleske\", 780),\n    (\"Stravinsky\", \"The Rite of Spring Sacrificial Dance\", [9], \"Stravinsky Rite of Spring Sacrificial Dance\", 300),\n    (\"Bartók\", \"Six Dances in Bulgarian Rhythm No 1\", [9], \"Bartok Bulgarian Rhythm No 1 Mikrokosmos\", 90),\n    # === 11/8 ===\n    (\"Traditional\", \"Gankino Horo\", [11], \"Gankino Horo Bulgarian 11/8\", 240),\n    (\"Traditional\", \"Kopanitsa\", [11], \"Kopanitsa Bulgarian folk 11/8\", 240),\n    (\"Traditional\", \"Ispayche\", [11], \"Ispayche Bulgarian 11/8\", 240),\n    (\"Primus\", \"Eleven\", [11], \"Primus Eleven\", 330),\n    (\"Grateful Dead\", \"The Eleven\", [11], \"Grateful Dead The Eleven\", 480),\n    (\"Bartók\", \"Six Dances in Bulgarian Rhythm No 6\", [11], \"Bartok Mikrokosmos 153 Bulgarian Rhythm 6\", 120),\n    (\"Aksak Maboul\", \"Saure Gurke\", [11], \"Aksak Maboul Saure Gurke\", 300),\n    (\"Frank Zappa\", \"Outside Now\", [11], \"Frank Zappa Outside Now\", 340),\n    # === Polyrhythmic (multi-label: e.g. [3,4] = both 3/x and 4/x active) ===\n    (\"Traditional\", \"Kpanlogo\", [3, 4], \"Kpanlogo Ghanaian drumming\", 300),\n    (\"Traditional\", \"Agbekor\", [3, 4], \"Agbekor Ewe drumming Ghana\", 300),\n    (\"Traditional\", \"Gahu\", [3, 4], \"Gahu drumming Ghana\", 300),\n    (\"Traditional\", \"Rumba Guaguancó\", [3, 4], \"Rumba Guaguanco Cuban\", 300),\n    (\"Traditional\", \"Bembe\", [3, 4], \"Bembe Cuban drumming 6/8 over 4/4\", 300),\n    (\"Traditional\", \"Afoxé\", [3, 4], \"Afoxe Brazilian rhythm\", 300),\n    (\"Fela Kuti\", \"Zombie\", [3, 4], \"Fela Kuti Zombie afrobeat\", 745),\n    (\"Fela Kuti\", \"Water No Get Enemy\", [3, 4], \"Fela Kuti Water No Get Enemy\", 600),\n    (\"Tony Allen\", \"Asiko\", [3, 4], \"Tony Allen Asiko afrobeat\", 360),\n    (\"Babatunde Olatunji\", \"Jin-Go-Lo-Ba\", [3, 4], \"Babatunde Olatunji Jingo\", 300),\n    (\"Talking Heads\", \"I Zimbra\", [3, 4], \"Talking Heads I Zimbra\", 195),\n    (\"Vampire Weekend\", \"Cape Cod Kwassa Kwassa\", [3, 4], None, 230),\n    (\"Chopin\", \"Fantaisie-Impromptu\", [3, 4], \"Chopin Fantaisie Impromptu\", 300),\n    (\"Debussy\", \"Clair de Lune\", [3, 4], \"Debussy Clair de Lune\", 330),\n    (\"Brahms\", \"Piano Concerto No 1 Rondo\", [3, 4], \"Brahms Piano Concerto 1 Rondo\", 600),\n    (\"Meshuggah\", \"Bleed\", [5, 4], \"Meshuggah Bleed\", 445),\n    (\"Meshuggah\", \"Rational Gaze\", [5, 4], None, 330),\n    (\"Meshuggah\", \"New Millennium Cyanide Christ\", [7, 4], None, 360),\n    (\"Traditional\", \"Gamelan Gong Kebyar\", [3, 4], \"Gamelan Gong Kebyar Bali\", 420),\n    (\"Traditional\", \"Gamelan Jegog\", [3, 4], \"Gamelan Jegog bamboo Bali\", 360),\n    (\"Traditional\", \"Djembe Dununba\", [3, 4], \"Dununba djembe rhythm West Africa\", 300),\n    (\"Traditional\", \"Sinte\", [3, 4], \"Sinte djembe rhythm Mande\", 300),\n    (\"Traditional\", \"Kuku\", [3, 4], \"Kuku djembe rhythm Guinea\", 300),\n]\n\n\ndef sanitize_filename(artist, title):\n    name = f\"{artist}_{title}\".lower()\n    name = re.sub(r\"[^\\w\\s-]\", \"\", name)\n    name = re.sub(r\"[\\s]+\", \"_\", name)\n    name = re.sub(r\"_+\", \"_\", name).strip(\"_\")\n    return name[:80]\n\n\ndef get_duration(path):\n    try:\n        result = subprocess.run(\n            [\"ffprobe\", \"-v\", \"quiet\", \"-print_format\", \"json\", \"-show_format\", str(path)],\n            capture_output=True, text=True, timeout=10)\n        return float(json.loads(result.stdout)[\"format\"][\"duration\"])\n    except Exception:\n        return None\n\n\ndef download_and_segment(query, stem, audio_dir, segment_length=30, expected_duration=None):\n    with tempfile.TemporaryDirectory() as tmpdir:\n        tmp_path = Path(tmpdir) / \"full.%(ext)s\"\n        if expected_duration:\n            min_dur = int(expected_duration / DURATION_TOLERANCE)\n            max_dur = int(expected_duration * DURATION_TOLERANCE)\n            duration_filter = f\"duration > {min_dur} & duration < {max_dur}\"\n        else:\n            duration_filter = f\"duration < {MAX_VIDEO_DURATION_FALLBACK}\"\n        cmd = [\"yt-dlp\", \"--default-search\", \"ytsearch1\", query,\n               \"-x\", \"--audio-format\", \"mp3\", \"--audio-quality\", \"5\",\n               \"-o\", str(tmp_path), \"--no-playlist\", \"--max-downloads\", \"1\",\n               \"--match-filter\", duration_filter,\n               \"--quiet\", \"--no-warnings\"]\n        try:\n            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)\n            if result.returncode not in (0, 101):\n                return []\n        except (subprocess.TimeoutExpired, FileNotFoundError):\n            return []\n\n        downloaded = list(Path(tmpdir).glob(\"full.*\"))\n        if not downloaded:\n            return []\n        src = downloaded[0]\n\n        duration = get_duration(src)\n        if not duration or duration < 15:\n            return []\n\n        margin = 10.0 if duration > 40 else 0.0\n        usable_start = margin\n        usable_duration = duration - 2 * margin\n        if usable_duration < 15:\n            usable_start = 0\n            usable_duration = duration\n\n        segments = []\n        seg_idx = 0\n        offset = 0.0\n        audio_dir.mkdir(parents=True, exist_ok=True)\n\n        while offset + 15 <= usable_duration and seg_idx < MAX_SEGMENTS:\n            seg_dur = min(segment_length, usable_duration - offset)\n            seg_stem = f\"{stem}_seg{seg_idx:02d}\"\n            dest = audio_dir / f\"{seg_stem}.mp3\"\n            ffmpeg_cmd = [\"ffmpeg\", \"-y\", \"-i\", str(src),\n                          \"-ss\", f\"{usable_start + offset:.1f}\",\n                          \"-t\", f\"{seg_dur:.1f}\",\n                          \"-acodec\", \"libmp3lame\", \"-ab\", \"192k\",\n                          \"-ar\", \"44100\", \"-ac\", \"1\", str(dest)]\n            try:\n                r = subprocess.run(ffmpeg_cmd, capture_output=True, text=True, timeout=60)\n                if r.returncode == 0 and dest.exists() and dest.stat().st_size > 1000:\n                    segments.append(seg_stem)\n            except subprocess.TimeoutExpired:\n                pass\n            offset += segment_length\n            seg_idx += 1\n\n        return segments\n\n\n# Download ALL songs including polyrhythmic (multi-label supported)\nprint(f\"Downloading {len(SONGS)} songs from YouTube...\")\nprint(f\"Max {MAX_SEGMENTS} segments per song, duration-filtered per song\\n\")\n\nsuccessful = []\nfor i, (artist, title, meters, query_override, exp_dur) in enumerate(SONGS, 1):\n    stem = sanitize_filename(artist, title)\n    query = query_override or f\"{artist} {title}\"\n    meter_str = \"+\".join(f\"{m}/x\" for m in meters)\n    print(f\"[{i:3d}/{len(SONGS)}] {artist} — {title} ({meter_str})\", end=\"\", flush=True)\n\n    existing = list(WIKIMETER_AUDIO.glob(f\"{stem}_seg*.mp3\"))\n    if existing:\n        n = min(len(existing), MAX_SEGMENTS)\n        for f in sorted(existing)[:n]:\n            successful.append((f.stem, meters))\n        print(f\" — skipped ({n} segs)\")\n        continue\n\n    segs = download_and_segment(query, stem, WIKIMETER_AUDIO, expected_duration=exp_dur)\n    if segs:\n        print(f\" — OK ({len(segs)} segs)\")\n        for s in segs:\n            successful.append((s, meters))\n    else:\n        print(\" — FAILED\")\n\nWIKIMETER_DIR.mkdir(parents=True, exist_ok=True)\nwith open(WIKIMETER_TAB, \"w\") as f:\n    f.write(\"filename\\tlabel\\tmeter\\talt_meter\\n\")\n    for stem, meters in successful:\n        primary = meters[0]\n        label = METER_LABELS.get(primary, str(primary))\n        meter_str = \",\".join(str(m) for m in meters)\n        f.write(f'\"/{stem}.mp3\"\\t\"{label}\"\\t{meter_str}\\t{primary * 2}\\n')\n\nprint(f\"\\nTotal: {len(successful)} segments saved to {WIKIMETER_TAB}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import average_precision_score, confusion_matrix, f1_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ── Constants ──\n",
    "CLASS_METERS = [3, 4, 5, 7, 9, 11]\n",
    "METER_TO_IDX = {m: i for i, m in enumerate(CLASS_METERS)}\n",
    "IDX_TO_METER = {i: m for i, m in enumerate(CLASS_METERS)}\n",
    "MERT_SR = 24000\n",
    "CHUNK_SAMPLES = 5 * MERT_SR\n",
    "MAX_DURATION_S = 30\n",
    "LABEL_SMOOTH_NEG = 0.1\n",
    "\n",
    "MODEL_CONFIGS = {\n",
    "    \"m-a-p/MERT-v1-95M\": (12, 768),\n",
    "    \"m-a-p/MERT-v1-330M\": (24, 1024),\n",
    "}\n",
    "\n",
    "\n",
    "# ── Data loading ──\n",
    "def resolve_audio_path(raw_fname, data_dir):\n",
    "    raw_fname = raw_fname.strip('\"').strip(\"'\").strip()\n",
    "    if not raw_fname:\n",
    "        return None\n",
    "    p = Path(raw_fname)\n",
    "    src_dir = p.parent.name\n",
    "    stem = p.stem\n",
    "    audio_dir = data_dir / \"audio\"\n",
    "    for ext in (\".mp3\", \".wav\", \".ogg\", \".flac\", p.suffix):\n",
    "        for candidate in [\n",
    "            audio_dir / f\"{stem}{ext}\",\n",
    "            audio_dir / f\"{src_dir}_{stem}{ext}\",\n",
    "            audio_dir / f\"{src_dir}_._{stem}{ext}\",\n",
    "        ]:\n",
    "            if candidate.exists():\n",
    "                return candidate\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_label_file(label_path, data_dir, valid_meters=None):\n",
    "    filename_cols = [\"filename\", \"file\", \"audio_file\", \"audio_path\", \"audio\", \"path\"]\n",
    "    label_cols = [\"meter\", \"time_signature\", \"ts\", \"time_sig\", \"signature\", \"label\"]\n",
    "    entries = []\n",
    "    with open(label_path, \"r\") as f:\n",
    "        first_line = f.readline()\n",
    "    delimiter = \"\\t\" if \"\\t\" in first_line else \",\"\n",
    "    with open(label_path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f, delimiter=delimiter)\n",
    "        if not reader.fieldnames:\n",
    "            return entries\n",
    "        header_map = {h.strip().lower().strip('\"'): h for h in reader.fieldnames}\n",
    "        fname_key = next((header_map[c] for c in filename_cols if c in header_map), None)\n",
    "        label_key = next((header_map[c] for c in label_cols if c in header_map), None)\n",
    "        if not fname_key or not label_key:\n",
    "            return entries\n",
    "        for row in reader:\n",
    "            raw_fname = row.get(fname_key, \"\").strip().strip('\"')\n",
    "            raw_label = row.get(label_key, \"\").strip().strip('\"')\n",
    "            if not raw_fname or not raw_label:\n",
    "                continue\n",
    "            try:\n",
    "                meter = int(raw_label.split(\"/\")[0].strip())\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if valid_meters and meter not in valid_meters:\n",
    "                continue\n",
    "            audio_path = resolve_audio_path(raw_fname, data_dir)\n",
    "            if audio_path:\n",
    "                entries.append((audio_path, meter))\n",
    "    return entries\n",
    "\n",
    "\n",
    "def load_split(data_dir, split):\n",
    "    valid = set(METER_TO_IDX.keys())\n",
    "    for ext in (\".tab\", \".csv\", \".tsv\"):\n",
    "        p = data_dir / f\"data_{split}_4_classes{ext}\"\n",
    "        if p.exists():\n",
    "            raw = parse_label_file(p, data_dir, valid)\n",
    "            entries = [(path, [m]) for path, m in raw]\n",
    "            print(f\"  {split}: {len(entries)} entries from {p.name}\")\n",
    "            return entries\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_extra_data(extra_dir):\n",
    "    extra_dir = Path(extra_dir)\n",
    "    valid = set(METER_TO_IDX.keys())\n",
    "    entries = []\n",
    "    for tab_file in sorted(extra_dir.glob(\"*.tab\")):\n",
    "        with open(tab_file, newline=\"\") as fh:\n",
    "            reader = csv.DictReader(fh, delimiter=\"\\t\")\n",
    "            for row in reader:\n",
    "                raw_fname = row.get(\"filename\", \"\").strip().strip('\"')\n",
    "                raw_meter = row.get(\"meter\", \"\").strip().strip('\"')\n",
    "                if not raw_fname or not raw_meter:\n",
    "                    continue\n",
    "                try:\n",
    "                    meters = [int(x) for x in raw_meter.split(\",\")]\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                meters = [m for m in meters if m in valid]\n",
    "                if not meters:\n",
    "                    continue\n",
    "                audio_path = resolve_audio_path(raw_fname, extra_dir)\n",
    "                if audio_path:\n",
    "                    entries.append((audio_path, meters))\n",
    "    return entries\n",
    "\n",
    "\n",
    "# ── Dataset ──\n",
    "class MERTAudioDataset(Dataset):\n",
    "    def __init__(self, entries, augment=False):\n",
    "        self.entries = [(p, m) for p, m in entries if p.exists() and any(x in METER_TO_IDX for x in m)]\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, meters = self.entries[idx]\n",
    "        label = np.full(len(CLASS_METERS), LABEL_SMOOTH_NEG, dtype=np.float32)\n",
    "        for m in meters:\n",
    "            if m in METER_TO_IDX:\n",
    "                label[METER_TO_IDX[m]] = 1.0\n",
    "        try:\n",
    "            audio, _ = librosa.load(str(path), sr=MERT_SR, mono=True)\n",
    "        except Exception:\n",
    "            audio = np.zeros(MERT_SR, dtype=np.float32)\n",
    "        max_samples = MAX_DURATION_S * MERT_SR\n",
    "        if len(audio) > max_samples:\n",
    "            if self.augment:\n",
    "                start = np.random.randint(0, len(audio) - max_samples)\n",
    "            else:\n",
    "                start = (len(audio) - max_samples) // 2\n",
    "            audio = audio[start:start + max_samples]\n",
    "        if len(audio) < MERT_SR:\n",
    "            audio = np.pad(audio, (0, MERT_SR - len(audio)))\n",
    "        if self.augment:\n",
    "            audio = audio + 0.005 * np.random.randn(len(audio)).astype(np.float32)\n",
    "            audio = np.roll(audio, np.random.randint(-MERT_SR // 2, MERT_SR // 2))\n",
    "        return audio.astype(np.float32), label\n",
    "\n",
    "\n",
    "def simple_collate(batch):\n",
    "    audios, labels = zip(*batch)\n",
    "    return list(audios), torch.tensor(np.stack(labels), dtype=torch.float32)\n",
    "\n",
    "\n",
    "# ── Model ──\n",
    "class MERTClassificationHead(nn.Module):\n",
    "    def __init__(self, num_layers, pooled_dim, num_classes=6, head_dim=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layer_logits = nn.Parameter(torch.zeros(num_layers))\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(pooled_dim),\n",
    "            nn.Linear(pooled_dim, head_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(head_dim, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, stacked):\n",
    "        w = torch.softmax(self.layer_logits, dim=0).view(1, self.num_layers, 1)\n",
    "        fused = (stacked * w).sum(dim=1)\n",
    "        return self.head(fused)\n",
    "\n",
    "\n",
    "def mert_forward_pool(audios, mert_model, processor, device, num_layers, hidden_dim):\n",
    "    batch_pooled = []\n",
    "    for audio_np in audios:\n",
    "        chunks = [audio_np[s:s + CHUNK_SAMPLES] for s in range(0, len(audio_np), CHUNK_SAMPLES)\n",
    "                  if len(audio_np[s:s + CHUNK_SAMPLES]) >= MERT_SR]\n",
    "        if not chunks:\n",
    "            chunks = [audio_np]\n",
    "        chunk_means = [[] for _ in range(num_layers)]\n",
    "        chunk_maxes = [[] for _ in range(num_layers)]\n",
    "        for chunk in chunks:\n",
    "            inputs = processor(chunk, sampling_rate=MERT_SR, return_tensors=\"pt\")\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = mert_model(**inputs)\n",
    "            for li in range(num_layers):\n",
    "                hs = outputs.hidden_states[li + 1].squeeze(0)\n",
    "                chunk_means[li].append(hs.mean(dim=0))\n",
    "                chunk_maxes[li].append(hs.max(dim=0).values)\n",
    "        layer_pooled = []\n",
    "        for li in range(num_layers):\n",
    "            mean_agg = torch.stack(chunk_means[li]).mean(dim=0)\n",
    "            max_agg = torch.stack(chunk_maxes[li]).max(dim=0).values\n",
    "            layer_pooled.append(torch.cat([mean_agg, max_agg]))\n",
    "        batch_pooled.append(torch.stack(layer_pooled))\n",
    "    return torch.stack(batch_pooled)\n",
    "\n",
    "\n",
    "# ── Training ──\n",
    "def train_one_epoch(mert_model, head, processor, loader, criterion, optimizer,\n",
    "                    device, num_layers, hidden_dim, grad_accum=1, use_lora=True):\n",
    "    head.train()\n",
    "    if use_lora:\n",
    "        mert_model.train()\n",
    "    total_loss = correct = total = 0\n",
    "    optimizer.zero_grad()\n",
    "    pbar = tqdm(loader, desc=\"Train\", leave=False)\n",
    "    for step, (audios, labels) in enumerate(pbar):\n",
    "        labels = labels.to(device)\n",
    "        if use_lora:\n",
    "            pooled = mert_forward_pool(audios, mert_model, processor, device, num_layers, hidden_dim)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pooled = mert_forward_pool(audios, mert_model, processor, device, num_layers, hidden_dim)\n",
    "            pooled = pooled.detach()\n",
    "        logits = head(pooled)\n",
    "        loss = criterion(logits, labels) / grad_accum\n",
    "        loss.backward()\n",
    "        if (step + 1) % grad_accum == 0 or step == len(loader) - 1:\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                list(head.parameters()) + [p for p in mert_model.parameters() if p.requires_grad], 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        total_loss += loss.item() * grad_accum * len(audios)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels.argmax(dim=1)).sum().item()\n",
    "        total += len(audios)\n",
    "        pbar.set_postfix_str(f\"loss={total_loss/total:.3f} acc={correct/total:.0%}\")\n",
    "    return total_loss / max(total, 1), correct / max(total, 1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(mert_model, head, processor, loader, criterion, device, num_layers, hidden_dim):\n",
    "    head.eval()\n",
    "    mert_model.eval()\n",
    "    total_loss = correct = total = 0\n",
    "    all_labels_idx, all_preds_idx = [], []\n",
    "    all_probs, all_labels_raw = [], []\n",
    "    for audios, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        labels = labels.to(device)\n",
    "        pooled = mert_forward_pool(audios, mert_model, processor, device, num_layers, hidden_dim)\n",
    "        logits = head(pooled)\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item() * len(audios)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        true_primary = labels.argmax(dim=1)\n",
    "        correct += (preds == true_primary).sum().item()\n",
    "        total += len(audios)\n",
    "        all_labels_idx.extend(true_primary.cpu().tolist())\n",
    "        all_preds_idx.extend(preds.cpu().tolist())\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "        all_labels_raw.append(labels.cpu().numpy())\n",
    "    return (total_loss / max(total, 1), correct / max(total, 1),\n",
    "            all_labels_idx, all_preds_idx,\n",
    "            np.concatenate(all_probs), np.concatenate(all_labels_raw))\n",
    "\n",
    "\n",
    "def print_eval_metrics(labels_idx, preds_idx, probs, labels_multihot):\n",
    "    meter_names = [f\"{m}/x\" for m in CLASS_METERS]\n",
    "    num_classes = len(CLASS_METERS)\n",
    "    true_primary = np.array(labels_idx)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(labels_idx, preds_idx, labels=list(range(num_classes)))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"          \" + \"  \".join(f\"{n:>6s}\" for n in meter_names))\n",
    "    for i, row in enumerate(cm):\n",
    "        row_str = \"  \".join(f\"{v:6d}\" for v in row)\n",
    "        acc = row[i] / row.sum() * 100 if row.sum() > 0 else 0\n",
    "        print(f\"  {meter_names[i]:>6s} | {row_str}   ({acc:5.1f}%)\")\n",
    "\n",
    "    # mAP\n",
    "    labels_binary = (labels_multihot > 0.5).astype(np.float32)\n",
    "    print(\"\\nMulti-label metrics:\")\n",
    "    aps = []\n",
    "    for i, m in enumerate(CLASS_METERS):\n",
    "        if labels_binary[:, i].sum() > 0:\n",
    "            ap = average_precision_score(labels_binary[:, i], probs[:, i])\n",
    "            aps.append(ap)\n",
    "            print(f\"  AP({m}/x): {ap:.3f}\")\n",
    "    if aps:\n",
    "        print(f\"  mAP: {np.mean(aps):.3f}\")\n",
    "\n",
    "    # Macro-F1\n",
    "    preds_binary = (probs > 0.5).astype(np.int32)\n",
    "    cols = [i for i in range(num_classes) if labels_binary[:, i].sum() > 0]\n",
    "    if cols:\n",
    "        print(f\"  Macro-F1: {f1_score(labels_binary[:, cols], preds_binary[:, cols], average='macro', zero_division=0):.3f}\")\n",
    "\n",
    "    # Confidence Gap\n",
    "    sorted_p = np.sort(probs, axis=1)[:, ::-1]\n",
    "    p_top1, p_top2 = sorted_p[:, 0], sorted_p[:, 1]\n",
    "    gaps = p_top1 - p_top2\n",
    "    print(f\"\\nConfidence Gap: mean={gaps.mean():.3f}, median={np.median(gaps):.3f}\")\n",
    "\n",
    "    # Entropy\n",
    "    eps = 1e-7\n",
    "    pc = np.clip(probs, eps, 1 - eps)\n",
    "    H = -(pc * np.log2(pc) + (1 - pc) * np.log2(1 - pc)).sum(axis=1)\n",
    "    H_norm = H / (num_classes * np.log2(2))\n",
    "    print(f\"H_norm: mean={H_norm.mean():.3f}, median={np.median(H_norm):.3f}\")\n",
    "\n",
    "    # Correlation\n",
    "    corr = np.corrcoef(probs.T)\n",
    "    pairs = []\n",
    "    for i in range(num_classes):\n",
    "        for j in range(i + 1, num_classes):\n",
    "            pairs.append((corr[i, j], f\"{CLASS_METERS[i]}/x↔{CLASS_METERS[j]}/x\"))\n",
    "    pairs.sort(key=lambda x: -abs(x[0]))\n",
    "    print(\"\\nTop correlations:\")\n",
    "    for r, name in pairs[:5]:\n",
    "        flag = \" ⚠\" if r > 0.3 else \"\"\n",
    "        print(f\"  {name}: r={r:+.3f}{flag}\")\n",
    "\n",
    "    # Noise floor\n",
    "    print(f\"\\nNoise Floor (P_top2): P95={np.percentile(p_top2, 95):.4f}, P99={np.percentile(p_top2, 99):.4f}\")\n",
    "\n",
    "print(\"Training code loaded ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure & run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ══════════════════════════════════════════════\n#  CONFIGURATION — edit these!\n# ══════════════════════════════════════════════\n\nMODEL_NAME = \"m-a-p/MERT-v1-330M\"  # or \"m-a-p/MERT-v1-95M\" for free T4\nEPOCHS = 30\nBATCH_SIZE = 4\nGRAD_ACCUM = 8\nLORA_RANK = 16\nLORA_ALPHA = 32\nUSE_LORA = True\nUSE_EXTRA_DATA = True\nCHECKPOINT_PATH = Path(\"/content/meter_mert_lora.pt\")\n\n# Auto-scale LR per model size\nLR_CONFIGS = {\n    \"m-a-p/MERT-v1-95M\":  {\"head_lr\": 5e-4, \"lora_lr\": 1e-4},\n    \"m-a-p/MERT-v1-330M\": {\"head_lr\": 1e-4, \"lora_lr\": 2e-5},\n}\nlr_cfg = LR_CONFIGS[MODEL_NAME]\nHEAD_LR = lr_cfg[\"head_lr\"]\nLORA_LR = lr_cfg[\"lora_lr\"]\n\n# ══════════════════════════════════════════════\n\ndevice = torch.device(\"cuda\")\nnum_layers, hidden_dim = MODEL_CONFIGS[MODEL_NAME]\npooled_dim = hidden_dim * 2\n\n# Load data\nprint(\"Loading data...\")\ntrain_entries = load_split(DATA_DIR, \"train\")\nval_entries = load_split(DATA_DIR, \"val\")\ntest_entries = load_split(DATA_DIR, \"test\")\n\nif USE_EXTRA_DATA and WIKIMETER_TAB.exists():\n    extra = load_extra_data(WIKIMETER_DIR)\n    print(f\"  Extra data: +{len(extra)} entries\")\n    train_entries.extend(extra)\n\n# Show distribution\ncounts = Counter()\nfor _, meters in train_entries + val_entries + test_entries:\n    for m in meters:\n        counts[m] += 1\nprint(f\"\\nTotal: {len(train_entries)} train, {len(val_entries)} val, {len(test_entries)} test\")\nfor m in CLASS_METERS:\n    print(f\"  Meter {m}: {counts.get(m, 0)}\")\n\n# Load model\nprint(f\"\\nLoading {MODEL_NAME}...\")\nfrom transformers import AutoModel, Wav2Vec2FeatureExtractor\nprocessor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_NAME, trust_remote_code=True)\nmert_model = AutoModel.from_pretrained(MODEL_NAME, trust_remote_code=True, output_hidden_states=True).to(device)\nprint(f\"  Parameters: {sum(p.numel() for p in mert_model.parameters())/1e6:.0f}M\")\n\n# LoRA\nif USE_LORA:\n    from peft import LoraConfig, get_peft_model\n    lora_config = LoraConfig(r=LORA_RANK, lora_alpha=LORA_ALPHA,\n                             target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\")\n    mert_model = get_peft_model(mert_model, lora_config)\n    trainable, total_p = mert_model.get_nb_trainable_parameters()\n    print(f\"  LoRA: {trainable:,} / {total_p:,} ({trainable/total_p:.2%})\")\nelse:\n    for p in mert_model.parameters():\n        p.requires_grad = False\n    print(\"  MERT frozen (no LoRA)\")\n\n# Head\nhead = MERTClassificationHead(num_layers, pooled_dim, len(CLASS_METERS)).to(device)\nprint(f\"  Head: {sum(p.numel() for p in head.parameters()):,} params\")\n\n# Data\ntrain_ds = MERTAudioDataset(train_entries, augment=True)\nval_ds = MERTAudioDataset(val_entries)\ntest_ds = MERTAudioDataset(test_entries)\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=simple_collate)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, collate_fn=simple_collate)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, collate_fn=simple_collate)\n\n# Loss\npos_counts = np.zeros(len(CLASS_METERS), dtype=np.float32)\nfor _, meters in train_ds.entries:\n    for m in meters:\n        if m in METER_TO_IDX:\n            pos_counts[METER_TO_IDX[m]] += 1\nneg_counts = len(train_ds) - pos_counts\nwith np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n    pos_weights = torch.tensor(np.where(pos_counts > 0, neg_counts / pos_counts, 1.0), dtype=torch.float32).to(device)\ncriterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\nprint(f\"Pos weights: {pos_weights.tolist()}\")\n\n# Optimizer\nparam_groups = [{\"params\": head.parameters(), \"lr\": HEAD_LR}]\nif USE_LORA:\n    lora_params = [p for p in mert_model.parameters() if p.requires_grad]\n    if lora_params:\n        param_groups.append({\"params\": lora_params, \"lr\": LORA_LR})\noptimizer = torch.optim.AdamW(param_groups, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n\nprint(f\"\\nReady! Model: {MODEL_NAME}\")\nprint(f\"  Head LR: {HEAD_LR}, LoRA LR: {LORA_LR}\")\nprint(f\"  Effective batch: {BATCH_SIZE * GRAD_ACCUM}\")\nprint(f\"  Datasets: {len(train_ds)} train, {len(val_ds)} val, {len(test_ds)} test\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ══════════════════════════════════════════════\n#  TRAINING LOOP\n# ══════════════════════════════════════════════\n\nbest_val_acc = 0.0\nbest_val_loss = float(\"inf\")\nbest_head_state = None\nbest_lora_state = None\npatience_counter = 0\nPATIENCE = 10\n\nprint(f\"{'Epoch':>5s}  {'TrainLoss':>10s}  {'TrainAcc':>9s}  {'ValLoss':>10s}  {'ValAcc':>9s}  {'Time':>6s}\")\nprint(\"-\" * 60)\n\nfor epoch in range(1, EPOCHS + 1):\n    t0 = time.time()\n\n    train_loss, train_acc = train_one_epoch(\n        mert_model, head, processor, train_loader, criterion, optimizer,\n        device, num_layers, hidden_dim, GRAD_ACCUM, USE_LORA)\n\n    val_loss, val_acc, _, _, _, _ = evaluate(\n        mert_model, head, processor, val_loader, criterion,\n        device, num_layers, hidden_dim)\n\n    scheduler.step()\n    elapsed = time.time() - t0\n\n    marker = \"\"\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        best_head_state = {k: v.cpu().clone() for k, v in head.state_dict().items()}\n        if USE_LORA:\n            best_lora_state = {n: p.cpu().clone() for n, p in mert_model.named_parameters() if p.requires_grad}\n        # Save to disk immediately so crashes don't lose progress\n        torch.save({\n            \"head_state_dict\": best_head_state,\n            \"lora_state_dict\": best_lora_state,\n            \"class_map\": IDX_TO_METER,\n            \"model_name\": MODEL_NAME,\n            \"num_layers\": num_layers,\n            \"hidden_dim\": hidden_dim,\n            \"pooled_dim\": pooled_dim,\n            \"head_dim\": 256,\n            \"num_classes\": len(CLASS_METERS),\n            \"dropout\": 0.3,\n            \"val_accuracy\": best_val_acc,\n            \"epoch\": epoch,\n            \"lora_rank\": LORA_RANK if USE_LORA else 0,\n            \"lora_alpha\": LORA_ALPHA if USE_LORA else 0,\n            \"model_type\": \"MERTFineTuned\",\n        }, CHECKPOINT_PATH)\n        marker = f\"  ** saved {CHECKPOINT_PATH.name}\"\n\n    print(f\"{epoch:5d}  {train_loss:10.4f}  {train_acc:8.1%}  {val_loss:10.4f}  {val_acc:8.1%}  {elapsed:5.0f}s{marker}\")\n\n    if val_loss < best_val_loss - 1e-4:\n        best_val_loss = val_loss\n        patience_counter = 0\n    else:\n        patience_counter += 1\n        if patience_counter >= PATIENCE:\n            print(f\"\\nEarly stopping at epoch {epoch}\")\n            break\n\nprint(f\"\\nBest val accuracy: {best_val_acc:.1%}\")\nif CHECKPOINT_PATH.exists():\n    print(f\"Checkpoint on disk: {CHECKPOINT_PATH} ({CHECKPOINT_PATH.stat().st_size / 1e6:.1f} MB)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "if best_head_state:\n",
    "    head.load_state_dict(best_head_state)\n",
    "    head = head.to(device)\n",
    "if best_lora_state:\n",
    "    for name, param_data in best_lora_state.items():\n",
    "        parts = name.split(\".\")\n",
    "        obj = mert_model\n",
    "        for part in parts[:-1]:\n",
    "            obj = getattr(obj, part)\n",
    "        getattr(obj, parts[-1]).data.copy_(param_data.to(device))\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc, test_labels, test_preds, test_probs, test_labels_mh = evaluate(\n",
    "    mert_model, head, processor, test_loader, criterion, device, num_layers, hidden_dim)\n",
    "\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_acc:.1%} ({sum(1 for a, b in zip(test_labels, test_preds) if a == b)}/{len(test_labels)})\")\n",
    "print(f\"Best val accuracy: {best_val_acc:.1%}\")\n",
    "\n",
    "print_eval_metrics(test_labels, test_preds, test_probs, test_labels_mh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save & download checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Checkpoint is already saved to disk during training.\n# This cell just verifies and triggers download.\n\nif CHECKPOINT_PATH.exists():\n    ckpt = torch.load(CHECKPOINT_PATH, weights_only=False)\n    print(f\"Checkpoint: {CHECKPOINT_PATH}\")\n    print(f\"  Model: {ckpt.get('model_name', '?')}\")\n    print(f\"  Best val: {ckpt.get('val_accuracy', 0):.1%} (epoch {ckpt.get('epoch', '?')})\")\n    print(f\"  Size: {CHECKPOINT_PATH.stat().st_size / 1e6:.1f} MB\")\n\n    # Run test eval with saved weights if not already done\n    if 'test_accuracy' not in ckpt:\n        print(\"\\nRunning test evaluation...\")\n        head.load_state_dict(ckpt[\"head_state_dict\"])\n        head = head.to(device)\n        if ckpt.get(\"lora_state_dict\"):\n            for name, param_data in ckpt[\"lora_state_dict\"].items():\n                parts = name.split(\".\")\n                obj = mert_model\n                for part in parts[:-1]:\n                    obj = getattr(obj, part)\n                getattr(obj, parts[-1]).data.copy_(param_data.to(device))\n\n        test_loss, test_acc, test_labels, test_preds, test_probs, test_labels_mh = evaluate(\n            mert_model, head, processor, test_loader, criterion, device, num_layers, hidden_dim)\n        print(f\"Test accuracy: {test_acc:.1%} ({sum(1 for a, b in zip(test_labels, test_preds) if a == b)}/{len(test_labels)})\")\n        print_eval_metrics(test_labels, test_preds, test_probs, test_labels_mh)\n\n        ckpt[\"test_accuracy\"] = test_acc\n        torch.save(ckpt, CHECKPOINT_PATH)\n\n    from google.colab import files\n    files.download(str(CHECKPOINT_PATH))\nelse:\n    print(\"No checkpoint found! Training may not have completed.\")"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}