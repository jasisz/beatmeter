{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERT LoRA Fine-tuning for Meter Classification\n",
    "\n",
    "**GPU**: Runtime → Change runtime type → T4 GPU (free) or A100 (Pro)\n",
    "\n",
    "This notebook:\n",
    "1. Downloads METER2800 dataset from Harvard Dataverse\n",
    "2. Downloads ODDMETER-WIKI (odd meter songs from YouTube)\n",
    "3. Fine-tunes MERT with LoRA for multi-label meter classification\n",
    "\n",
    "**Estimated time**: ~2-3h on T4 (95M), ~5h on A100 (330M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers peft librosa scikit-learn tqdm yt-dlp\n",
    "!apt-get -qq install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'NO GPU'}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"No GPU! Go to Runtime → Change runtime type → T4 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download METER2800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import ssl\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"/content/data/meter2800\")\n",
    "AUDIO_DIR = DATA_DIR / \"audio\"\n",
    "DOWNLOADS_DIR = DATA_DIR / \"downloads\"\n",
    "AUDIO_EXTENSIONS = {\".wav\", \".mp3\", \".ogg\", \".flac\", \".oga\", \".opus\", \".aiff\", \".aif\"}\n",
    "\n",
    "DOI = \"doi:10.7910/DVN/0CLXBQ\"\n",
    "API_BASE = \"https://dataverse.harvard.edu/api\"\n",
    "DATASET_URL = f\"{API_BASE}/datasets/:persistentId/?persistentId={DOI}\"\n",
    "TAR_FILES = {\"FMA.tar.gz\", \"MAG.tar.gz\", \"OWN.tar.gz\"}\n",
    "\n",
    "\n",
    "def api_request(url, max_retries=3):\n",
    "    ctx = ssl.create_default_context()\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            req = urllib.request.Request(url, headers={\"User-Agent\": \"RhythmAnalyzer/1.0\", \"Accept\": \"application/json\"})\n",
    "            with urllib.request.urlopen(req, timeout=30, context=ctx) as resp:\n",
    "                return resp.read()\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 * (2 ** attempt))\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "\n",
    "def download_dataverse_file(file_id, dest, expected_size=0):\n",
    "    url = f\"{API_BASE}/access/datafile/{file_id}\"\n",
    "    ctx = ssl.create_default_context()\n",
    "    req = urllib.request.Request(url, headers={\"User-Agent\": \"RhythmAnalyzer/1.0\"})\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with urllib.request.urlopen(req, timeout=300, context=ctx) as resp:\n",
    "        dest.write_bytes(resp.read())\n",
    "    return dest.exists()\n",
    "\n",
    "\n",
    "def extract_tar(tar_path, audio_dir):\n",
    "    audio_dir.mkdir(parents=True, exist_ok=True)\n",
    "    count = 0\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if not member.isfile():\n",
    "                continue\n",
    "            name = Path(member.name).name\n",
    "            if Path(name).suffix.lower() not in AUDIO_EXTENSIONS:\n",
    "                continue\n",
    "            dest = audio_dir / name\n",
    "            if dest.exists():\n",
    "                parent = Path(member.name).parent.name\n",
    "                dest = audio_dir / f\"{parent}_{name}\"\n",
    "            with tar.extractfile(member) as src:\n",
    "                if src:\n",
    "                    dest.write_bytes(src.read())\n",
    "                    count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "# Check if already downloaded\n",
    "if AUDIO_DIR.exists() and len(list(AUDIO_DIR.glob(\"*\"))) > 2000:\n",
    "    print(f\"METER2800 already downloaded: {len(list(AUDIO_DIR.glob('*')))} files\")\n",
    "else:\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    DOWNLOADS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    AUDIO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get file list\n",
    "    print(\"Fetching METER2800 metadata...\")\n",
    "    metadata = json.loads(api_request(DATASET_URL))\n",
    "    files = metadata[\"data\"][\"latestVersion\"][\"files\"]\n",
    "    print(f\"Found {len(files)} files\")\n",
    "\n",
    "    for f in files:\n",
    "        df = f[\"dataFile\"]\n",
    "        fname = df[\"filename\"]\n",
    "\n",
    "        if fname in TAR_FILES:\n",
    "            dest = DOWNLOADS_DIR / fname\n",
    "            if not dest.exists():\n",
    "                print(f\"Downloading {fname}...\", end=\" \", flush=True)\n",
    "                download_dataverse_file(df[\"id\"], dest, df.get(\"filesize\", 0))\n",
    "                print(\"OK\")\n",
    "        elif fname.endswith((\".csv\", \".tab\", \".tsv\")):\n",
    "            dest = DATA_DIR / fname\n",
    "            if not dest.exists():\n",
    "                print(f\"Downloading {fname}...\", end=\" \", flush=True)\n",
    "                download_dataverse_file(df[\"id\"], dest)\n",
    "                print(\"OK\")\n",
    "\n",
    "    # Extract\n",
    "    total = 0\n",
    "    for tar_path in sorted(DOWNLOADS_DIR.glob(\"*.tar.gz\")):\n",
    "        if tar_path.name in TAR_FILES:\n",
    "            print(f\"Extracting {tar_path.name}...\", end=\" \", flush=True)\n",
    "            count = extract_tar(tar_path, AUDIO_DIR)\n",
    "            print(f\"{count} files\")\n",
    "            total += count\n",
    "    print(f\"\\nTotal extracted: {total} audio files\")\n",
    "\n",
    "# Verify\n",
    "n_audio = len([f for f in AUDIO_DIR.iterdir() if f.suffix.lower() in AUDIO_EXTENSIONS])\n",
    "n_tabs = len(list(DATA_DIR.glob(\"*.tab\")))\n",
    "print(f\"\\nMETER2800: {n_audio} audio files, {n_tabs} label files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download ODDMETER-WIKI (YouTube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import re\nimport subprocess\nimport tempfile\n\nODDMETER_DIR = Path(\"/content/data/oddmeter-wiki\")\nODDMETER_AUDIO = ODDMETER_DIR / \"audio\"\nODDMETER_TAB = ODDMETER_DIR / \"data_oddmeter_wiki.tab\"\nMETER_LABELS = {3: \"three\", 4: \"four\", 5: \"five\", 7: \"seven\", 9: \"nine\", 11: \"eleven\"}\nMAX_SEGMENTS = 25  # Cap: max 25 × 30s = 12.5 min per song\n\nSONGS = [\n    # 5/x\n    (\"Dave Brubeck\", \"Take Five\", [5], None),\n    (\"Paul Desmond\", \"Take Ten\", [5], \"Paul Desmond Take Ten\"),\n    (\"Brubeck\", \"Three to Get Ready\", [5], \"Dave Brubeck Three to Get Ready\"),\n    (\"Chick Corea\", \"Spain\", [5], \"Chick Corea Spain\"),\n    (\"Radiohead\", \"15 Step\", [5], None),\n    (\"Radiohead\", \"Morning Bell\", [5], None),\n    (\"Radiohead\", \"Everything in Its Right Place\", [5], None),\n    (\"Radiohead\", \"Sail to the Moon\", [5], None),\n    (\"Gorillaz\", \"5/4\", [5], \"Gorillaz 5/4\"),\n    (\"Jethro Tull\", \"Living in the Past\", [5], None),\n    (\"Sting\", \"Seven Days\", [5], None),\n    (\"Nick Drake\", \"River Man\", [5], None),\n    (\"The Mars Volta\", \"Inertiatic ESP\", [5], None),\n    (\"Sufjan Stevens\", \"A Good Man Is Hard to Find\", [5], None),\n    (\"Donovan\", \"Atlantis\", [5], None),\n    (\"Soundgarden\", \"My Wave\", [5], \"Soundgarden My Wave\"),\n    (\"Tame Impala\", \"Apocalypse Dreams\", [5], None),\n    (\"Lalo Schifrin\", \"Mission Impossible Theme\", [5], \"Mission Impossible theme original\"),\n    (\"Chopin\", \"Piano Sonata No 1 Larghetto\", [5], \"Chopin Piano Sonata No 1 Op 4 Larghetto 5/4\"),\n    (\"Tchaikovsky\", \"Symphony No 6 Movement 2\", [5], \"Tchaikovsky Symphony 6 second movement 5/4\"),\n    (\"Dream Theater\", \"The Mirror\", [5], None),\n    (\"Animals as Leaders\", \"CAFO\", [5], None),\n    (\"King Crimson\", \"Discipline\", [5], \"King Crimson Discipline\"),\n    (\"Björk\", \"Army of Me\", [5], None),\n    (\"Béla Fleck\", \"Sinister Minister\", [5], \"Bela Fleck Sinister Minister\"),\n    (\"Mike Oldfield\", \"Tubular Bells Part 1\", [5], \"Mike Oldfield Tubular Bells opening 5/4\"),\n    (\"Vulfpeck\", \"Dean Town\", [5], None),\n    (\"Jacob Collier\", \"In My Room\", [5], \"Jacob Collier In My Room\"),\n    (\"Traditional\", \"Eleno Mome\", [5], \"Eleno Mome Bulgarian folk\"),\n    (\"Traditional\", \"Paidushko Horo\", [5], \"Paidushko Horo Bulgarian folk\"),\n    # 7/x\n    (\"Pink Floyd\", \"Money\", [7], None),\n    (\"Peter Gabriel\", \"Solsbury Hill\", [7], None),\n    (\"Soundgarden\", \"Outshined\", [7], \"Soundgarden Outshined\"),\n    (\"The Beatles\", \"All You Need Is Love\", [7], \"Beatles All You Need Is Love\"),\n    (\"Radiohead\", \"2 + 2 = 5\", [7], \"Radiohead 2+2=5\"),\n    (\"Rush\", \"Tom Sawyer\", [7], \"Rush Tom Sawyer\"),\n    (\"Gentle Giant\", \"The Runaway\", [7], \"Gentle Giant The Runaway\"),\n    (\"Alice in Chains\", \"Them Bones\", [7], \"Alice in Chains Them Bones\"),\n    (\"King Crimson\", \"Frame by Frame\", [7], \"King Crimson Frame by Frame\"),\n    (\"Opeth\", \"The Drapery Falls\", [7], None),\n    (\"Gentle Giant\", \"Knots\", [7], \"Gentle Giant Knots\"),\n    (\"Robert Fripp\", \"Exposure\", [7], \"Robert Fripp Exposure\"),\n    (\"Dave Holland\", \"Conference of the Birds\", [7], \"Dave Holland Conference of the Birds\"),\n    (\"John McLaughlin\", \"Meeting of the Spirits\", [7], \"Mahavishnu Orchestra Meeting of the Spirits\"),\n    (\"Traditional\", \"Rachenitsa\", [7], \"Rachenitsa Bulgarian folk 7/8\"),\n    (\"Traditional\", \"Makedonsko Devojche\", [7], \"Makedonsko Devojche folk 7/8\"),\n    (\"Traditional\", \"Chetvorno Horo\", [7], \"Chetvorno Horo Bulgarian 7/8\"),\n    (\"Traditional\", \"Lesnoto\", [7], \"Lesnoto Macedonian 7/8\"),\n    (\"Traditional\", \"Ivailo\", [7], \"Ivailo Bulgarian folk 7/8\"),\n    (\"Traditional\", \"Pravo Horo\", [7], \"Pravo Horo Bulgarian\"),\n    (\"Goran Bregović\", \"Mesečina\", [7], \"Goran Bregovic Mesecina\"),\n    (\"Fanfare Ciocărlia\", \"Born to Be Wild\", [7], \"Fanfare Ciocarlia Born to Be Wild\"),\n    (\"Bernstein\", \"America from West Side Story\", [7], \"Bernstein America West Side Story\"),\n    (\"Hans Zimmer\", \"Mombasa\", [7], \"Hans Zimmer Mombasa Inception\"),\n    (\"Bear McCreary\", \"BSG Main Theme\", [7], \"Bear McCreary Battlestar Galactica theme\"),\n    (\"Aimee Mann\", \"Momentum\", [7], None),\n    (\"Joni Mitchell\", \"The Silky Veils of Ardor\", [7], None),\n    (\"Broken Social Scene\", \"7/4 Shoreline\", [7], \"Broken Social Scene 7/4 Shoreline\"),\n    (\"Iron Maiden\", \"The Loneliness of the Long Distance Runner\", [7], None),\n    (\"Led Zeppelin\", \"The Ocean\", [7], \"Led Zeppelin The Ocean\"),\n    (\"Jeff Beck\", \"Led Boots\", [7], None),\n    (\"Porcupine Tree\", \"The Sound of Muzak\", [7], None),\n    # 9/x\n    (\"Dave Brubeck\", \"Blue Rondo à la Turk\", [9], \"Dave Brubeck Blue Rondo a la Turk\"),\n    (\"Traditional\", \"Daichovo Horo\", [9], \"Daichovo Horo Bulgarian 9/8\"),\n    (\"Traditional\", \"Zeimbekiko\", [9], \"Zeimbekiko Greek dance 9/8\"),\n    (\"Traditional\", \"Karsilama\", [9], \"Karsilama Turkish 9/8\"),\n    (\"Traditional\", \"Arap\", [9], \"Arap Turkish 9/8 dance\"),\n    (\"Bartók\", \"Six Dances in Bulgarian Rhythm No 4\", [9], \"Bartok Mikrokosmos 151 Bulgarian Rhythm 4\"),\n    (\"Bartók\", \"Six Dances in Bulgarian Rhythm No 5\", [9], \"Bartok Mikrokosmos 152 Bulgarian Rhythm 5\"),\n    (\"Toto\", \"Mushanga\", [9], \"Toto Mushanga\"),\n    (\"Muse\", \"Butterflies and Hurricanes\", [9], \"Muse Butterflies and Hurricanes\"),\n    (\"Mahler\", \"Symphony No 9 Rondo Burleske\", [9], \"Mahler Symphony 9 Rondo Burleske\"),\n    (\"Stravinsky\", \"The Rite of Spring Sacrificial Dance\", [9], \"Stravinsky Rite of Spring Sacrificial Dance\"),\n    (\"Bartók\", \"Six Dances in Bulgarian Rhythm No 1\", [9], \"Bartok Bulgarian Rhythm No 1 Mikrokosmos\"),\n    # 11/x\n    (\"Traditional\", \"Gankino Horo\", [11], \"Gankino Horo Bulgarian 11/8\"),\n    (\"Traditional\", \"Kopanitsa\", [11], \"Kopanitsa Bulgarian folk 11/8\"),\n    (\"Traditional\", \"Ispayche\", [11], \"Ispayche Bulgarian 11/8\"),\n    (\"Primus\", \"Eleven\", [11], \"Primus Eleven\"),\n    (\"Grateful Dead\", \"The Eleven\", [11], \"Grateful Dead The Eleven\"),\n    (\"Bartók\", \"Six Dances in Bulgarian Rhythm No 6\", [11], \"Bartok Mikrokosmos 153 Bulgarian Rhythm 6\"),\n    (\"Aksak Maboul\", \"Saure Gurke\", [11], \"Aksak Maboul Saure Gurke\"),\n    (\"Frank Zappa\", \"Outside Now\", [11], \"Frank Zappa Outside Now\"),\n    # Polyrhythmic (multi-label)\n    (\"Traditional\", \"Kpanlogo\", [3, 4], \"Kpanlogo Ghanaian drumming\"),\n    (\"Traditional\", \"Agbekor\", [3, 4], \"Agbekor Ewe drumming Ghana\"),\n    (\"Traditional\", \"Gahu\", [3, 4], \"Gahu drumming Ghana\"),\n    (\"Traditional\", \"Rumba Guaguancó\", [3, 4], \"Rumba Guaguanco Cuban\"),\n    (\"Traditional\", \"Bembe\", [3, 4], \"Bembe Cuban drumming 6/8 over 4/4\"),\n    (\"Traditional\", \"Afoxé\", [3, 4], \"Afoxe Brazilian rhythm\"),\n    (\"Fela Kuti\", \"Zombie\", [3, 4], \"Fela Kuti Zombie afrobeat\"),\n    (\"Fela Kuti\", \"Water No Get Enemy\", [3, 4], \"Fela Kuti Water No Get Enemy\"),\n    (\"Tony Allen\", \"Asiko\", [3, 4], \"Tony Allen Asiko afrobeat\"),\n    (\"Babatunde Olatunji\", \"Jin-Go-Lo-Ba\", [3, 4], \"Babatunde Olatunji Jingo\"),\n    (\"Talking Heads\", \"I Zimbra\", [3, 4], \"Talking Heads I Zimbra\"),\n    (\"Vampire Weekend\", \"Cape Cod Kwassa Kwassa\", [3, 4], None),\n    (\"Chopin\", \"Fantaisie-Impromptu\", [3, 4], \"Chopin Fantaisie Impromptu\"),\n    (\"Debussy\", \"Clair de Lune\", [3, 4], \"Debussy Clair de Lune\"),\n    (\"Brahms\", \"Piano Concerto No 1 Rondo\", [3, 4], \"Brahms Piano Concerto 1 Rondo\"),\n    (\"Meshuggah\", \"Bleed\", [5, 4], \"Meshuggah Bleed\"),\n    (\"Meshuggah\", \"Rational Gaze\", [5, 4], None),\n    (\"Meshuggah\", \"New Millennium Cyanide Christ\", [7, 4], None),\n    (\"Traditional\", \"Gamelan Gong Kebyar\", [3, 4], \"Gamelan Gong Kebyar Bali\"),\n    (\"Traditional\", \"Gamelan Jegog\", [3, 4], \"Gamelan Jegog bamboo Bali\"),\n    (\"Traditional\", \"Djembe Dununba\", [3, 4], \"Dununba djembe rhythm West Africa\"),\n    (\"Traditional\", \"Sinte\", [3, 4], \"Sinte djembe rhythm Mande\"),\n    (\"Traditional\", \"Kuku\", [3, 4], \"Kuku djembe rhythm Guinea\"),\n]\n\n\ndef sanitize_filename(artist, title):\n    name = f\"{artist}_{title}\".lower()\n    name = re.sub(r\"[^\\w\\s-]\", \"\", name)\n    name = re.sub(r\"[\\s]+\", \"_\", name)\n    name = re.sub(r\"_+\", \"_\", name).strip(\"_\")\n    return name[:80]\n\n\ndef get_duration(path):\n    try:\n        result = subprocess.run(\n            [\"ffprobe\", \"-v\", \"quiet\", \"-print_format\", \"json\", \"-show_format\", str(path)],\n            capture_output=True, text=True, timeout=10)\n        return float(json.loads(result.stdout)[\"format\"][\"duration\"])\n    except Exception:\n        return None\n\n\ndef download_and_segment(query, stem, audio_dir, segment_length=30):\n    with tempfile.TemporaryDirectory() as tmpdir:\n        tmp_path = Path(tmpdir) / \"full.%(ext)s\"\n        cmd = [\"yt-dlp\", \"--default-search\", \"ytsearch1\", query,\n               \"-x\", \"--audio-format\", \"mp3\", \"--audio-quality\", \"5\",\n               \"-o\", str(tmp_path), \"--no-playlist\", \"--max-downloads\", \"1\",\n               \"--match-filter\", \"duration < 600\",\n               \"--quiet\", \"--no-warnings\"]\n        try:\n            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)\n            if result.returncode not in (0, 101):\n                return []\n        except (subprocess.TimeoutExpired, FileNotFoundError):\n            return []\n\n        downloaded = list(Path(tmpdir).glob(\"full.*\"))\n        if not downloaded:\n            return []\n        src = downloaded[0]\n\n        duration = get_duration(src)\n        if not duration or duration < 15:\n            return []\n\n        margin = 10.0 if duration > 40 else 0.0\n        usable_start = margin\n        usable_duration = duration - 2 * margin\n        if usable_duration < 15:\n            usable_start = 0\n            usable_duration = duration\n\n        segments = []\n        seg_idx = 0\n        offset = 0.0\n        audio_dir.mkdir(parents=True, exist_ok=True)\n\n        while offset + 15 <= usable_duration and seg_idx < MAX_SEGMENTS:\n            seg_dur = min(segment_length, usable_duration - offset)\n            seg_stem = f\"{stem}_seg{seg_idx:02d}\"\n            dest = audio_dir / f\"{seg_stem}.mp3\"\n            ffmpeg_cmd = [\"ffmpeg\", \"-y\", \"-i\", str(src),\n                          \"-ss\", f\"{usable_start + offset:.1f}\",\n                          \"-t\", f\"{seg_dur:.1f}\",\n                          \"-acodec\", \"libmp3lame\", \"-ab\", \"192k\",\n                          \"-ar\", \"44100\", \"-ac\", \"1\", str(dest)]\n            try:\n                r = subprocess.run(ffmpeg_cmd, capture_output=True, text=True, timeout=60)\n                if r.returncode == 0 and dest.exists() and dest.stat().st_size > 1000:\n                    segments.append(seg_stem)\n            except subprocess.TimeoutExpired:\n                pass\n            offset += segment_length\n            seg_idx += 1\n\n        return segments\n\n\nprint(f\"Downloading {len(SONGS)} songs from YouTube...\")\nprint(f\"Max {MAX_SEGMENTS} segments per song, skipping videos > 10 min\\n\")\n\nsuccessful = []\nfor i, (artist, title, meters, query_override) in enumerate(SONGS, 1):\n    stem = sanitize_filename(artist, title)\n    query = query_override or f\"{artist} {title}\"\n    print(f\"[{i:3d}/{len(SONGS)}] {artist} — {title}\", end=\"\", flush=True)\n\n    # Skip if exists\n    existing = list(ODDMETER_AUDIO.glob(f\"{stem}_seg*.mp3\"))\n    if existing:\n        n = min(len(existing), MAX_SEGMENTS)\n        for f in sorted(existing)[:n]:\n            successful.append((f.stem, meters))\n        print(f\" — skipped ({n} segs)\")\n        continue\n\n    segs = download_and_segment(query, stem, ODDMETER_AUDIO)\n    if segs:\n        print(f\" — OK ({len(segs)} segs)\")\n        for s in segs:\n            successful.append((s, meters))\n    else:\n        print(\" — FAILED\")\n\n# Write .tab\nODDMETER_DIR.mkdir(parents=True, exist_ok=True)\nwith open(ODDMETER_TAB, \"w\") as f:\n    f.write(\"filename\\tlabel\\tmeter\\talt_meter\\n\")\n    for stem, meters in successful:\n        primary = meters[0]\n        label = METER_LABELS.get(primary, str(primary))\n        meter_str = \",\".join(str(m) for m in meters)\n        f.write(f'\"/{stem}.mp3\"\\t\"{label}\"\\t{meter_str}\\t{primary * 2}\\n')\n\nprint(f\"\\nTotal: {len(successful)} segments saved to {ODDMETER_TAB}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import average_precision_score, confusion_matrix, f1_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ── Constants ──\n",
    "CLASS_METERS = [3, 4, 5, 7, 9, 11]\n",
    "METER_TO_IDX = {m: i for i, m in enumerate(CLASS_METERS)}\n",
    "IDX_TO_METER = {i: m for i, m in enumerate(CLASS_METERS)}\n",
    "MERT_SR = 24000\n",
    "CHUNK_SAMPLES = 5 * MERT_SR\n",
    "MAX_DURATION_S = 30\n",
    "LABEL_SMOOTH_NEG = 0.1\n",
    "\n",
    "MODEL_CONFIGS = {\n",
    "    \"m-a-p/MERT-v1-95M\": (12, 768),\n",
    "    \"m-a-p/MERT-v1-330M\": (24, 1024),\n",
    "}\n",
    "\n",
    "\n",
    "# ── Data loading ──\n",
    "def resolve_audio_path(raw_fname, data_dir):\n",
    "    raw_fname = raw_fname.strip('\"').strip(\"'\").strip()\n",
    "    if not raw_fname:\n",
    "        return None\n",
    "    p = Path(raw_fname)\n",
    "    src_dir = p.parent.name\n",
    "    stem = p.stem\n",
    "    audio_dir = data_dir / \"audio\"\n",
    "    for ext in (\".mp3\", \".wav\", \".ogg\", \".flac\", p.suffix):\n",
    "        for candidate in [\n",
    "            audio_dir / f\"{stem}{ext}\",\n",
    "            audio_dir / f\"{src_dir}_{stem}{ext}\",\n",
    "            audio_dir / f\"{src_dir}_._{stem}{ext}\",\n",
    "        ]:\n",
    "            if candidate.exists():\n",
    "                return candidate\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_label_file(label_path, data_dir, valid_meters=None):\n",
    "    filename_cols = [\"filename\", \"file\", \"audio_file\", \"audio_path\", \"audio\", \"path\"]\n",
    "    label_cols = [\"meter\", \"time_signature\", \"ts\", \"time_sig\", \"signature\", \"label\"]\n",
    "    entries = []\n",
    "    with open(label_path, \"r\") as f:\n",
    "        first_line = f.readline()\n",
    "    delimiter = \"\\t\" if \"\\t\" in first_line else \",\"\n",
    "    with open(label_path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f, delimiter=delimiter)\n",
    "        if not reader.fieldnames:\n",
    "            return entries\n",
    "        header_map = {h.strip().lower().strip('\"'): h for h in reader.fieldnames}\n",
    "        fname_key = next((header_map[c] for c in filename_cols if c in header_map), None)\n",
    "        label_key = next((header_map[c] for c in label_cols if c in header_map), None)\n",
    "        if not fname_key or not label_key:\n",
    "            return entries\n",
    "        for row in reader:\n",
    "            raw_fname = row.get(fname_key, \"\").strip().strip('\"')\n",
    "            raw_label = row.get(label_key, \"\").strip().strip('\"')\n",
    "            if not raw_fname or not raw_label:\n",
    "                continue\n",
    "            try:\n",
    "                meter = int(raw_label.split(\"/\")[0].strip())\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if valid_meters and meter not in valid_meters:\n",
    "                continue\n",
    "            audio_path = resolve_audio_path(raw_fname, data_dir)\n",
    "            if audio_path:\n",
    "                entries.append((audio_path, meter))\n",
    "    return entries\n",
    "\n",
    "\n",
    "def load_split(data_dir, split):\n",
    "    valid = set(METER_TO_IDX.keys())\n",
    "    for ext in (\".tab\", \".csv\", \".tsv\"):\n",
    "        p = data_dir / f\"data_{split}_4_classes{ext}\"\n",
    "        if p.exists():\n",
    "            raw = parse_label_file(p, data_dir, valid)\n",
    "            entries = [(path, [m]) for path, m in raw]\n",
    "            print(f\"  {split}: {len(entries)} entries from {p.name}\")\n",
    "            return entries\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_extra_data(extra_dir):\n",
    "    extra_dir = Path(extra_dir)\n",
    "    valid = set(METER_TO_IDX.keys())\n",
    "    entries = []\n",
    "    for tab_file in sorted(extra_dir.glob(\"*.tab\")):\n",
    "        with open(tab_file, newline=\"\") as fh:\n",
    "            reader = csv.DictReader(fh, delimiter=\"\\t\")\n",
    "            for row in reader:\n",
    "                raw_fname = row.get(\"filename\", \"\").strip().strip('\"')\n",
    "                raw_meter = row.get(\"meter\", \"\").strip().strip('\"')\n",
    "                if not raw_fname or not raw_meter:\n",
    "                    continue\n",
    "                try:\n",
    "                    meters = [int(x) for x in raw_meter.split(\",\")]\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                meters = [m for m in meters if m in valid]\n",
    "                if not meters:\n",
    "                    continue\n",
    "                audio_path = resolve_audio_path(raw_fname, extra_dir)\n",
    "                if audio_path:\n",
    "                    entries.append((audio_path, meters))\n",
    "    return entries\n",
    "\n",
    "\n",
    "# ── Dataset ──\n",
    "class MERTAudioDataset(Dataset):\n",
    "    def __init__(self, entries, augment=False):\n",
    "        self.entries = [(p, m) for p, m in entries if p.exists() and any(x in METER_TO_IDX for x in m)]\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, meters = self.entries[idx]\n",
    "        label = np.full(len(CLASS_METERS), LABEL_SMOOTH_NEG, dtype=np.float32)\n",
    "        for m in meters:\n",
    "            if m in METER_TO_IDX:\n",
    "                label[METER_TO_IDX[m]] = 1.0\n",
    "        try:\n",
    "            audio, _ = librosa.load(str(path), sr=MERT_SR, mono=True)\n",
    "        except Exception:\n",
    "            audio = np.zeros(MERT_SR, dtype=np.float32)\n",
    "        max_samples = MAX_DURATION_S * MERT_SR\n",
    "        if len(audio) > max_samples:\n",
    "            if self.augment:\n",
    "                start = np.random.randint(0, len(audio) - max_samples)\n",
    "            else:\n",
    "                start = (len(audio) - max_samples) // 2\n",
    "            audio = audio[start:start + max_samples]\n",
    "        if len(audio) < MERT_SR:\n",
    "            audio = np.pad(audio, (0, MERT_SR - len(audio)))\n",
    "        if self.augment:\n",
    "            audio = audio + 0.005 * np.random.randn(len(audio)).astype(np.float32)\n",
    "            audio = np.roll(audio, np.random.randint(-MERT_SR // 2, MERT_SR // 2))\n",
    "        return audio.astype(np.float32), label\n",
    "\n",
    "\n",
    "def simple_collate(batch):\n",
    "    audios, labels = zip(*batch)\n",
    "    return list(audios), torch.tensor(np.stack(labels), dtype=torch.float32)\n",
    "\n",
    "\n",
    "# ── Model ──\n",
    "class MERTClassificationHead(nn.Module):\n",
    "    def __init__(self, num_layers, pooled_dim, num_classes=6, head_dim=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.layer_logits = nn.Parameter(torch.zeros(num_layers))\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(pooled_dim),\n",
    "            nn.Linear(pooled_dim, head_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(head_dim, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, stacked):\n",
    "        w = torch.softmax(self.layer_logits, dim=0).view(1, self.num_layers, 1)\n",
    "        fused = (stacked * w).sum(dim=1)\n",
    "        return self.head(fused)\n",
    "\n",
    "\n",
    "def mert_forward_pool(audios, mert_model, processor, device, num_layers, hidden_dim):\n",
    "    batch_pooled = []\n",
    "    for audio_np in audios:\n",
    "        chunks = [audio_np[s:s + CHUNK_SAMPLES] for s in range(0, len(audio_np), CHUNK_SAMPLES)\n",
    "                  if len(audio_np[s:s + CHUNK_SAMPLES]) >= MERT_SR]\n",
    "        if not chunks:\n",
    "            chunks = [audio_np]\n",
    "        chunk_means = [[] for _ in range(num_layers)]\n",
    "        chunk_maxes = [[] for _ in range(num_layers)]\n",
    "        for chunk in chunks:\n",
    "            inputs = processor(chunk, sampling_rate=MERT_SR, return_tensors=\"pt\")\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = mert_model(**inputs)\n",
    "            for li in range(num_layers):\n",
    "                hs = outputs.hidden_states[li + 1].squeeze(0)\n",
    "                chunk_means[li].append(hs.mean(dim=0))\n",
    "                chunk_maxes[li].append(hs.max(dim=0).values)\n",
    "        layer_pooled = []\n",
    "        for li in range(num_layers):\n",
    "            mean_agg = torch.stack(chunk_means[li]).mean(dim=0)\n",
    "            max_agg = torch.stack(chunk_maxes[li]).max(dim=0).values\n",
    "            layer_pooled.append(torch.cat([mean_agg, max_agg]))\n",
    "        batch_pooled.append(torch.stack(layer_pooled))\n",
    "    return torch.stack(batch_pooled)\n",
    "\n",
    "\n",
    "# ── Training ──\n",
    "def train_one_epoch(mert_model, head, processor, loader, criterion, optimizer,\n",
    "                    device, num_layers, hidden_dim, grad_accum=1, use_lora=True):\n",
    "    head.train()\n",
    "    if use_lora:\n",
    "        mert_model.train()\n",
    "    total_loss = correct = total = 0\n",
    "    optimizer.zero_grad()\n",
    "    pbar = tqdm(loader, desc=\"Train\", leave=False)\n",
    "    for step, (audios, labels) in enumerate(pbar):\n",
    "        labels = labels.to(device)\n",
    "        if use_lora:\n",
    "            pooled = mert_forward_pool(audios, mert_model, processor, device, num_layers, hidden_dim)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pooled = mert_forward_pool(audios, mert_model, processor, device, num_layers, hidden_dim)\n",
    "            pooled = pooled.detach()\n",
    "        logits = head(pooled)\n",
    "        loss = criterion(logits, labels) / grad_accum\n",
    "        loss.backward()\n",
    "        if (step + 1) % grad_accum == 0 or step == len(loader) - 1:\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                list(head.parameters()) + [p for p in mert_model.parameters() if p.requires_grad], 1.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        total_loss += loss.item() * grad_accum * len(audios)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels.argmax(dim=1)).sum().item()\n",
    "        total += len(audios)\n",
    "        pbar.set_postfix_str(f\"loss={total_loss/total:.3f} acc={correct/total:.0%}\")\n",
    "    return total_loss / max(total, 1), correct / max(total, 1)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(mert_model, head, processor, loader, criterion, device, num_layers, hidden_dim):\n",
    "    head.eval()\n",
    "    mert_model.eval()\n",
    "    total_loss = correct = total = 0\n",
    "    all_labels_idx, all_preds_idx = [], []\n",
    "    all_probs, all_labels_raw = [], []\n",
    "    for audios, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        labels = labels.to(device)\n",
    "        pooled = mert_forward_pool(audios, mert_model, processor, device, num_layers, hidden_dim)\n",
    "        logits = head(pooled)\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item() * len(audios)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        true_primary = labels.argmax(dim=1)\n",
    "        correct += (preds == true_primary).sum().item()\n",
    "        total += len(audios)\n",
    "        all_labels_idx.extend(true_primary.cpu().tolist())\n",
    "        all_preds_idx.extend(preds.cpu().tolist())\n",
    "        all_probs.append(probs.cpu().numpy())\n",
    "        all_labels_raw.append(labels.cpu().numpy())\n",
    "    return (total_loss / max(total, 1), correct / max(total, 1),\n",
    "            all_labels_idx, all_preds_idx,\n",
    "            np.concatenate(all_probs), np.concatenate(all_labels_raw))\n",
    "\n",
    "\n",
    "def print_eval_metrics(labels_idx, preds_idx, probs, labels_multihot):\n",
    "    meter_names = [f\"{m}/x\" for m in CLASS_METERS]\n",
    "    num_classes = len(CLASS_METERS)\n",
    "    true_primary = np.array(labels_idx)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(labels_idx, preds_idx, labels=list(range(num_classes)))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"          \" + \"  \".join(f\"{n:>6s}\" for n in meter_names))\n",
    "    for i, row in enumerate(cm):\n",
    "        row_str = \"  \".join(f\"{v:6d}\" for v in row)\n",
    "        acc = row[i] / row.sum() * 100 if row.sum() > 0 else 0\n",
    "        print(f\"  {meter_names[i]:>6s} | {row_str}   ({acc:5.1f}%)\")\n",
    "\n",
    "    # mAP\n",
    "    labels_binary = (labels_multihot > 0.5).astype(np.float32)\n",
    "    print(\"\\nMulti-label metrics:\")\n",
    "    aps = []\n",
    "    for i, m in enumerate(CLASS_METERS):\n",
    "        if labels_binary[:, i].sum() > 0:\n",
    "            ap = average_precision_score(labels_binary[:, i], probs[:, i])\n",
    "            aps.append(ap)\n",
    "            print(f\"  AP({m}/x): {ap:.3f}\")\n",
    "    if aps:\n",
    "        print(f\"  mAP: {np.mean(aps):.3f}\")\n",
    "\n",
    "    # Macro-F1\n",
    "    preds_binary = (probs > 0.5).astype(np.int32)\n",
    "    cols = [i for i in range(num_classes) if labels_binary[:, i].sum() > 0]\n",
    "    if cols:\n",
    "        print(f\"  Macro-F1: {f1_score(labels_binary[:, cols], preds_binary[:, cols], average='macro', zero_division=0):.3f}\")\n",
    "\n",
    "    # Confidence Gap\n",
    "    sorted_p = np.sort(probs, axis=1)[:, ::-1]\n",
    "    p_top1, p_top2 = sorted_p[:, 0], sorted_p[:, 1]\n",
    "    gaps = p_top1 - p_top2\n",
    "    print(f\"\\nConfidence Gap: mean={gaps.mean():.3f}, median={np.median(gaps):.3f}\")\n",
    "\n",
    "    # Entropy\n",
    "    eps = 1e-7\n",
    "    pc = np.clip(probs, eps, 1 - eps)\n",
    "    H = -(pc * np.log2(pc) + (1 - pc) * np.log2(1 - pc)).sum(axis=1)\n",
    "    H_norm = H / (num_classes * np.log2(2))\n",
    "    print(f\"H_norm: mean={H_norm.mean():.3f}, median={np.median(H_norm):.3f}\")\n",
    "\n",
    "    # Correlation\n",
    "    corr = np.corrcoef(probs.T)\n",
    "    pairs = []\n",
    "    for i in range(num_classes):\n",
    "        for j in range(i + 1, num_classes):\n",
    "            pairs.append((corr[i, j], f\"{CLASS_METERS[i]}/x↔{CLASS_METERS[j]}/x\"))\n",
    "    pairs.sort(key=lambda x: -abs(x[0]))\n",
    "    print(\"\\nTop correlations:\")\n",
    "    for r, name in pairs[:5]:\n",
    "        flag = \" ⚠\" if r > 0.3 else \"\"\n",
    "        print(f\"  {name}: r={r:+.3f}{flag}\")\n",
    "\n",
    "    # Noise floor\n",
    "    print(f\"\\nNoise Floor (P_top2): P95={np.percentile(p_top2, 95):.4f}, P99={np.percentile(p_top2, 99):.4f}\")\n",
    "\n",
    "print(\"Training code loaded ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configure & run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════\n",
    "#  CONFIGURATION — edit these!\n",
    "# ══════════════════════════════════════════════\n",
    "\n",
    "MODEL_NAME = \"m-a-p/MERT-v1-95M\"   # or \"m-a-p/MERT-v1-330M\" on A100\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 4\n",
    "GRAD_ACCUM = 8\n",
    "HEAD_LR = 5e-4\n",
    "LORA_LR = 1e-4\n",
    "LORA_RANK = 16\n",
    "LORA_ALPHA = 32\n",
    "USE_LORA = True\n",
    "USE_EXTRA_DATA = True\n",
    "CHECKPOINT_PATH = Path(\"/content/meter_mert_lora.pt\")\n",
    "\n",
    "# ══════════════════════════════════════════════\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "num_layers, hidden_dim = MODEL_CONFIGS[MODEL_NAME]\n",
    "pooled_dim = hidden_dim * 2\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "train_entries = load_split(DATA_DIR, \"train\")\n",
    "val_entries = load_split(DATA_DIR, \"val\")\n",
    "test_entries = load_split(DATA_DIR, \"test\")\n",
    "\n",
    "if USE_EXTRA_DATA and ODDMETER_TAB.exists():\n",
    "    extra = load_extra_data(ODDMETER_DIR)\n",
    "    print(f\"  Extra data: +{len(extra)} entries\")\n",
    "    train_entries.extend(extra)\n",
    "\n",
    "# Show distribution\n",
    "counts = Counter()\n",
    "for _, meters in train_entries + val_entries + test_entries:\n",
    "    for m in meters:\n",
    "        counts[m] += 1\n",
    "print(f\"\\nTotal: {len(train_entries)} train, {len(val_entries)} val, {len(test_entries)} test\")\n",
    "for m in CLASS_METERS:\n",
    "    print(f\"  Meter {m}: {counts.get(m, 0)}\")\n",
    "\n",
    "# Load model\n",
    "print(f\"\\nLoading {MODEL_NAME}...\")\n",
    "from transformers import AutoModel, Wav2Vec2FeatureExtractor\n",
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "mert_model = AutoModel.from_pretrained(MODEL_NAME, trust_remote_code=True, output_hidden_states=True).to(device)\n",
    "print(f\"  Parameters: {sum(p.numel() for p in mert_model.parameters())/1e6:.0f}M\")\n",
    "\n",
    "# LoRA\n",
    "if USE_LORA:\n",
    "    from peft import LoraConfig, get_peft_model\n",
    "    lora_config = LoraConfig(r=LORA_RANK, lora_alpha=LORA_ALPHA,\n",
    "                             target_modules=[\"q_proj\", \"v_proj\"], lora_dropout=0.05, bias=\"none\")\n",
    "    mert_model = get_peft_model(mert_model, lora_config)\n",
    "    trainable, total_p = mert_model.get_nb_trainable_parameters()\n",
    "    print(f\"  LoRA: {trainable:,} / {total_p:,} ({trainable/total_p:.2%})\")\n",
    "else:\n",
    "    for p in mert_model.parameters():\n",
    "        p.requires_grad = False\n",
    "    print(\"  MERT frozen (no LoRA)\")\n",
    "\n",
    "# Head\n",
    "head = MERTClassificationHead(num_layers, pooled_dim, len(CLASS_METERS)).to(device)\n",
    "print(f\"  Head: {sum(p.numel() for p in head.parameters()):,} params\")\n",
    "\n",
    "# Data\n",
    "train_ds = MERTAudioDataset(train_entries, augment=True)\n",
    "val_ds = MERTAudioDataset(val_entries)\n",
    "test_ds = MERTAudioDataset(test_entries)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=simple_collate)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, collate_fn=simple_collate)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, collate_fn=simple_collate)\n",
    "\n",
    "# Loss\n",
    "pos_counts = np.zeros(len(CLASS_METERS), dtype=np.float32)\n",
    "for _, meters in train_ds.entries:\n",
    "    for m in meters:\n",
    "        if m in METER_TO_IDX:\n",
    "            pos_counts[METER_TO_IDX[m]] += 1\n",
    "neg_counts = len(train_ds) - pos_counts\n",
    "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "    pos_weights = torch.tensor(np.where(pos_counts > 0, neg_counts / pos_counts, 1.0), dtype=torch.float32).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "print(f\"Pos weights: {pos_weights.tolist()}\")\n",
    "\n",
    "# Optimizer\n",
    "param_groups = [{\"params\": head.parameters(), \"lr\": HEAD_LR}]\n",
    "if USE_LORA:\n",
    "    lora_params = [p for p in mert_model.parameters() if p.requires_grad]\n",
    "    if lora_params:\n",
    "        param_groups.append({\"params\": lora_params, \"lr\": LORA_LR})\n",
    "optimizer = torch.optim.AdamW(param_groups, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "print(f\"\\nReady! Optimizer: head lr={HEAD_LR}, LoRA lr={LORA_LR}\")\n",
    "print(f\"Effective batch: {BATCH_SIZE * GRAD_ACCUM}\")\n",
    "print(f\"Datasets: {len(train_ds)} train, {len(val_ds)} val, {len(test_ds)} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════\n",
    "#  TRAINING LOOP\n",
    "# ══════════════════════════════════════════════\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_val_loss = float(\"inf\")\n",
    "best_head_state = None\n",
    "best_lora_state = None\n",
    "patience_counter = 0\n",
    "PATIENCE = 10\n",
    "\n",
    "print(f\"{'Epoch':>5s}  {'TrainLoss':>10s}  {'TrainAcc':>9s}  {'ValLoss':>10s}  {'ValAcc':>9s}  {'Time':>6s}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        mert_model, head, processor, train_loader, criterion, optimizer,\n",
    "        device, num_layers, hidden_dim, GRAD_ACCUM, USE_LORA)\n",
    "\n",
    "    val_loss, val_acc, _, _, _, _ = evaluate(\n",
    "        mert_model, head, processor, val_loader, criterion,\n",
    "        device, num_layers, hidden_dim)\n",
    "\n",
    "    scheduler.step()\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    print(f\"{epoch:5d}  {train_loss:10.4f}  {train_acc:8.1%}  {val_loss:10.4f}  {val_acc:8.1%}  {elapsed:5.0f}s\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_head_state = {k: v.cpu().clone() for k, v in head.state_dict().items()}\n",
    "        if USE_LORA:\n",
    "            best_lora_state = {n: p.cpu().clone() for n, p in mert_model.named_parameters() if p.requires_grad}\n",
    "\n",
    "    if val_loss < best_val_loss - 1e-4:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nBest val accuracy: {best_val_acc:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "if best_head_state:\n",
    "    head.load_state_dict(best_head_state)\n",
    "    head = head.to(device)\n",
    "if best_lora_state:\n",
    "    for name, param_data in best_lora_state.items():\n",
    "        parts = name.split(\".\")\n",
    "        obj = mert_model\n",
    "        for part in parts[:-1]:\n",
    "            obj = getattr(obj, part)\n",
    "        getattr(obj, parts[-1]).data.copy_(param_data.to(device))\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc, test_labels, test_preds, test_probs, test_labels_mh = evaluate(\n",
    "    mert_model, head, processor, test_loader, criterion, device, num_layers, hidden_dim)\n",
    "\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_acc:.1%} ({sum(1 for a, b in zip(test_labels, test_preds) if a == b)}/{len(test_labels)})\")\n",
    "print(f\"Best val accuracy: {best_val_acc:.1%}\")\n",
    "\n",
    "print_eval_metrics(test_labels, test_preds, test_probs, test_labels_mh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save & download checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    \"head_state_dict\": best_head_state or head.state_dict(),\n",
    "    \"class_map\": IDX_TO_METER,\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"pooled_dim\": pooled_dim,\n",
    "    \"head_dim\": 256,\n",
    "    \"num_classes\": len(CLASS_METERS),\n",
    "    \"dropout\": 0.3,\n",
    "    \"val_accuracy\": best_val_acc,\n",
    "    \"test_accuracy\": test_acc,\n",
    "    \"lora_rank\": LORA_RANK if USE_LORA else 0,\n",
    "    \"lora_alpha\": LORA_ALPHA if USE_LORA else 0,\n",
    "    \"model_type\": \"MERTFineTuned\",\n",
    "}\n",
    "if best_lora_state:\n",
    "    checkpoint[\"lora_state_dict\"] = best_lora_state\n",
    "\n",
    "torch.save(checkpoint, CHECKPOINT_PATH)\n",
    "print(f\"Checkpoint saved: {CHECKPOINT_PATH}\")\n",
    "print(f\"  Val: {best_val_acc:.1%}, Test: {test_acc:.1%}\")\n",
    "\n",
    "# Download to local machine\n",
    "from google.colab import files\n",
    "files.download(str(CHECKPOINT_PATH))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}